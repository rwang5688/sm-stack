{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (1.24.30)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.30 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from boto3) (1.27.30)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from boto3) (0.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.30->boto3) (1.26.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.30->boto3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.30->boto3) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sagemaker in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (2.99.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (21.0)\n",
      "Requirement already satisfied: google-pasta in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: pandas in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (1.3.2)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (4.8.1)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (3.18.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: pathos in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (0.2.9)\n",
      "Requirement already satisfied: attrs<22,>=20.3.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (21.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.20.21 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (1.24.30)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (1.20.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.30 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (1.27.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.30->boto3<2.0,>=1.20.21->sagemaker) (1.26.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.30->boto3<2.0,>=1.20.21->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->sagemaker) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from pandas->sagemaker) (2021.1)\n",
      "Requirement already satisfied: pox>=0.3.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.1)\n",
      "Requirement already satisfied: multiprocess>=0.70.13 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from pathos->sagemaker) (0.70.13)\n",
      "Requirement already satisfied: ppft>=1.7.6.5 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from pathos->sagemaker) (1.7.6.5)\n",
      "Requirement already satisfied: dill>=0.3.5.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sagemaker in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (2.99.0)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (21.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: google-pasta in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (4.8.1)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: attrs<22,>=20.3.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (21.2.0)\n",
      "Requirement already satisfied: pandas in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (1.3.2)\n",
      "Requirement already satisfied: pathos in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (0.2.9)\n",
      "Requirement already satisfied: boto3<2.0,>=1.20.21 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (1.24.30)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (1.20.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.30 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (1.27.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.30->boto3<2.0,>=1.20.21->sagemaker) (1.26.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.30->boto3<2.0,>=1.20.21->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->sagemaker) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from pandas->sagemaker) (2021.1)\n",
      "Requirement already satisfied: multiprocess>=0.70.13 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from pathos->sagemaker) (0.70.13)\n",
      "Requirement already satisfied: dill>=0.3.5.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.5.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.5 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from pathos->sagemaker) (1.7.6.5)\n",
      "Requirement already satisfied: pox>=0.3.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchmetrics in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (0.9.2)\n",
      "Requirement already satisfied: packaging in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from torchmetrics) (21.0)\n",
      "Requirement already satisfied: torch>=1.3.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from torchmetrics) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from torchmetrics) (1.20.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from torch>=1.3.1->torchmetrics) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from packaging->torchmetrics) (2.4.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install packages\n",
    "%pip install boto3\n",
    "%pip install sagemaker\n",
    "%pip install -U sagemaker\n",
    "%pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 01\n",
    "import os\n",
    "import sagemaker\n",
    "import torchmetrics\n",
    "import torch\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = 'AmazonSageMaker-ExecutionRole-20220714T204241'\n",
    "# role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 02\n",
    "training_data_uri = 's3://multibert-8b87f872-a3fe-4a19-a016-e02402275450/training/multi_label_new.csv'\n",
    "#test_data_uri = 's3://multibert-8b87f872-a3fe-4a19-a016-e02402275450/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 05\n",
    "pytorch_estimator = PyTorch('multibert.py',\n",
    "                            instance_type='ml.c5.2xlarge',\n",
    "                            instance_count=2,\n",
    "                            role = role,\n",
    "                            framework_version='1.11.0',\n",
    "                            py_version='py38',\n",
    "                            source_dir = 'code',\n",
    "                            hyperparameters = {'epochs': 4, 'batch-size': 32, 'learning-rate': 2e-05})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-17 00:20:39 Starting - Starting the training job...\n",
      "2022-07-17 00:20:54 Starting - Preparing the instances for trainingProfilerReport-1658017238: InProgress\n",
      "......\n",
      "2022-07-17 00:22:13 Downloading - Downloading input data\n",
      "2022-07-17 00:22:13 Training - Downloading the training image........\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-07-17 00:23:30,774 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-07-17 00:23:30,776 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-17 00:23:30,782 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-07-17 00:23:30,787 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-17 00:23:30,793 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-07-17 00:23:31,106 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.11.0+cpu)\u001b[0m\n",
      "\u001b[34mCollecting watermark\u001b[0m\n",
      "\u001b[34mDownloading watermark-2.3.1-py2.py3-none-any.whl (7.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting transformers\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.4/4.4 MB 54.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pytorch-lightning\u001b[0m\n",
      "\u001b[34mDownloading pytorch_lightning-1.6.5-py3-none-any.whl (585 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 585.9/585.9 kB 53.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting colored\u001b[0m\n",
      "\u001b[34mDownloading colored-1.4.3.tar.gz (29 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35m2022-07-17 00:23:30,882 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2022-07-17 00:23:30,883 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-07-17 00:23:30,890 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2022-07-17 00:23:30,897 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-07-17 00:23:30,905 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2022-07-17 00:23:31,219 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.11.0+cpu)\u001b[0m\n",
      "\u001b[35mCollecting watermark\u001b[0m\n",
      "\u001b[35mDownloading watermark-2.3.1-py2.py3-none-any.whl (7.2 kB)\u001b[0m\n",
      "\u001b[35mCollecting transformers\u001b[0m\n",
      "\u001b[35mDownloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.4/4.4 MB 49.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting pytorch-lightning\u001b[0m\n",
      "\u001b[35mDownloading pytorch_lightning-1.6.5-py3-none-any.whl (585 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 585.9/585.9 kB 49.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting colored\u001b[0m\n",
      "\u001b[35mDownloading colored-1.4.3.tar.gz (29 kB)\u001b[0m\n",
      "\u001b[35mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting torchmetrics\u001b[0m\n",
      "\u001b[34mDownloading torchmetrics-0.9.2-py3-none-any.whl (419 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 419.7/419.7 kB 22.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch->-r requirements.txt (line 1)) (4.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ipython in /opt/conda/lib/python3.8/site-packages (from watermark->-r requirements.txt (line 2)) (8.1.0)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.5/101.5 kB 11.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (2.28.1)\u001b[0m\n",
      "\u001b[35mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mCollecting torchmetrics\u001b[0m\n",
      "\u001b[35mDownloading torchmetrics-0.9.2-py3-none-any.whl (419 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 419.7/419.7 kB 25.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch->-r requirements.txt (line 1)) (4.2.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: ipython in /opt/conda/lib/python3.8/site-packages (from watermark->-r requirements.txt (line 2)) (8.1.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (5.4.1)\u001b[0m\n",
      "\u001b[35mCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[35mDownloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 84.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (21.3)\u001b[0m\n",
      "\u001b[35mCollecting filelock\u001b[0m\n",
      "\u001b[35mDownloading filelock-3.7.1-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (1.23.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (4.64.0)\u001b[0m\n",
      "\u001b[35mCollecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[35mDownloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.5/101.5 kB 9.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 103.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[34mDownloading regex-2022.7.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (765 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 765.0/765.0 kB 61.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (4.64.0)\u001b[0m\n",
      "\u001b[34mCollecting filelock\u001b[0m\n",
      "\u001b[34mDownloading filelock-3.7.1-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (21.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (1.23.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<=3.20.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 4)) (3.19.4)\u001b[0m\n",
      "\u001b[34mCollecting pyDeprecate>=0.3.1\u001b[0m\n",
      "\u001b[34mDownloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 4)) (2022.5.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard>=2.2.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.8/5.8 MB 106.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[35mDownloading regex-2022.7.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (765 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 765.0/765.0 kB 41.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (2.28.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 4)) (2022.5.0)\u001b[0m\n",
      "\u001b[35mCollecting pyDeprecate>=0.3.1\u001b[0m\n",
      "\u001b[35mDownloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: protobuf<=3.20.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 4)) (3.19.4)\u001b[0m\n",
      "\u001b[35mCollecting tensorboard>=2.2.0\u001b[0m\n",
      "\u001b[35mDownloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.8/5.8 MB 108.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting aiohttp\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.8.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 75.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers->-r requirements.txt (line 3)) (3.0.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (0.37.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (62.6.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 45.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34mDownloading google_auth-2.9.1-py2.py3-none-any.whl (167 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 167.8/167.8 kB 38.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34mDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34mDownloading absl_py-1.1.0-py3-none-any.whl (123 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.7/123.7 kB 11.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34mDownloading Markdown-3.4.1-py3-none-any.whl (93 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.3/93.3 kB 23.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 109.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting aiohttp\u001b[0m\n",
      "\u001b[35mDownloading aiohttp-3.8.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 78.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers->-r requirements.txt (line 3)) (3.0.9)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (0.37.1)\u001b[0m\n",
      "\u001b[35mCollecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[35mDownloading google_auth-2.9.1-py2.py3-none-any.whl (167 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 167.8/167.8 kB 17.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting absl-py>=0.4\u001b[0m\n",
      "\u001b[35mDownloading absl_py-1.1.0-py3-none-any.whl (123 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.7/123.7 kB 27.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[35mDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 106.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (2.1.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (62.6.0)\u001b[0m\n",
      "\u001b[35mCollecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[35mDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[35mCollecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[35mDownloading Markdown-3.4.1-py3-none-any.whl (93 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.3/93.3 kB 21.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[35mDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 59.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[34mDownloading grpcio-1.47.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 121.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 3)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 3)) (1.26.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 3)) (2022.6.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 3)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (4.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.7.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.18.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (5.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (3.0.30)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (2.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: stack-data in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (5.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34mDownloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 15.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34mDownloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (4.7.2)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34mDownloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython->watermark->-r requirements.txt (line 2)) (0.8.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (4.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython->watermark->-r requirements.txt (line 2)) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->watermark->-r requirements.txt (line 2)) (0.2.5)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.7.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (308 kB)\u001b[0m\n",
      "\u001b[35mCollecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[35mDownloading grpcio-1.47.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 116.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 3)) (3.3)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 3)) (1.26.9)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 3)) (2.1.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 3)) (2022.6.15)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.7.5)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: stack-data in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.3.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (2.12.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.18.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (4.8.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (5.3.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.2.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.1.3)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (5.1.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (3.0.30)\u001b[0m\n",
      "\u001b[35mCollecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[35mDownloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 14.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[35mDownloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (1.16.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (4.7.2)\u001b[0m\n",
      "\u001b[35mCollecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[35mDownloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython->watermark->-r requirements.txt (line 2)) (0.8.3)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (4.12.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython->watermark->-r requirements.txt (line 2)) (0.7.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->watermark->-r requirements.txt (line 2)) (0.2.5)\u001b[0m\n",
      "\u001b[35mCollecting yarl<2.0,>=1.0\u001b[0m\n",
      "\u001b[35mDownloading yarl-1.7.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (308 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 308.6/308.6 kB 37.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 4)) (20.3.0)\u001b[0m\n",
      "\u001b[35mCollecting aiosignal>=1.1.2\u001b[0m\n",
      "\u001b[35mDownloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\u001b[0m\n",
      "\u001b[35mCollecting frozenlist>=1.1.1\u001b[0m\n",
      "\u001b[35mDownloading frozenlist-1.3.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\u001b[0m\n",
      "\n",
      "2022-07-17 00:23:41 Training - Training image download completed. Training in progress.\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 308.6/308.6 kB 39.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.1.2\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<5.0,>=4.0.0a3\u001b[0m\n",
      "\u001b[34mDownloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.3/121.3 kB 28.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.3.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 158.7/158.7 kB 23.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 4)) (20.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pure-eval in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->watermark->-r requirements.txt (line 2)) (0.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: executing in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->watermark->-r requirements.txt (line 2)) (0.8.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: asttokens in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->watermark->-r requirements.txt (line 2)) (2.0.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (3.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (0.4.8)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34mDownloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.5/151.5 kB 36.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: colored\u001b[0m\n",
      "\u001b[34mBuilding wheel for colored (setup.py): started\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 158.7/158.7 kB 26.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting multidict<7.0,>=4.5\u001b[0m\n",
      "\u001b[35mDownloading multidict-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.3/121.3 kB 29.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting async-timeout<5.0,>=4.0.0a3\u001b[0m\n",
      "\u001b[35mDownloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: asttokens in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->watermark->-r requirements.txt (line 2)) (2.0.5)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pure-eval in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->watermark->-r requirements.txt (line 2)) (0.2.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: executing in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->watermark->-r requirements.txt (line 2)) (0.8.3)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (3.8.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (0.4.8)\u001b[0m\n",
      "\u001b[35mCollecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[35mDownloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.5/151.5 kB 23.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: colored\u001b[0m\n",
      "\u001b[35mBuilding wheel for colored (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for colored (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for colored: filename=colored-1.4.3-py3-none-any.whl size=14323 sha256=d2961ac994fb87c483885c6fbf28d8fe137ede6e8beffaf898ce4db6f534beeb\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/b3/cf/a4/23200f342c1291c99b34a54e4997a6cd9ed23f58a924ddaa49\u001b[0m\n",
      "\u001b[34mSuccessfully built colored\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tokenizers, tensorboard-plugin-wit, colored, tensorboard-data-server, regex, pyDeprecate, pyasn1-modules, oauthlib, multidict, grpcio, frozenlist, filelock, cachetools, async-timeout, absl-py, yarl, torchmetrics, requests-oauthlib, markdown, huggingface-hub, google-auth, aiosignal, transformers, google-auth-oauthlib, aiohttp, watermark, tensorboard, pytorch-lightning\u001b[0m\n",
      "\u001b[35mBuilding wheel for colored (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mCreated wheel for colored: filename=colored-1.4.3-py3-none-any.whl size=14323 sha256=d2961ac994fb87c483885c6fbf28d8fe137ede6e8beffaf898ce4db6f534beeb\u001b[0m\n",
      "\u001b[35mStored in directory: /root/.cache/pip/wheels/b3/cf/a4/23200f342c1291c99b34a54e4997a6cd9ed23f58a924ddaa49\u001b[0m\n",
      "\u001b[35mSuccessfully built colored\u001b[0m\n",
      "\u001b[35mInstalling collected packages: tokenizers, tensorboard-plugin-wit, colored, tensorboard-data-server, regex, pyDeprecate, pyasn1-modules, oauthlib, multidict, grpcio, frozenlist, filelock, cachetools, async-timeout, absl-py, yarl, torchmetrics, requests-oauthlib, markdown, huggingface-hub, google-auth, aiosignal, transformers, google-auth-oauthlib, aiohttp, watermark, tensorboard, pytorch-lightning\u001b[0m\n",
      "\u001b[34mSuccessfully installed absl-py-1.1.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 cachetools-5.2.0 colored-1.4.3 filelock-3.7.1 frozenlist-1.3.0 google-auth-2.9.1 google-auth-oauthlib-0.4.6 grpcio-1.47.0 huggingface-hub-0.8.1 markdown-3.4.1 multidict-6.0.2 oauthlib-3.2.0 pyDeprecate-0.3.2 pyasn1-modules-0.2.8 pytorch-lightning-1.6.5 regex-2022.7.9 requests-oauthlib-1.3.1 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tokenizers-0.12.1 torchmetrics-0.9.2 transformers-4.20.1 watermark-2.3.1 yarl-1.7.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35mSuccessfully installed absl-py-1.1.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 cachetools-5.2.0 colored-1.4.3 filelock-3.7.1 frozenlist-1.3.0 google-auth-2.9.1 google-auth-oauthlib-0.4.6 grpcio-1.47.0 huggingface-hub-0.8.1 markdown-3.4.1 multidict-6.0.2 oauthlib-3.2.0 pyDeprecate-0.3.2 pyasn1-modules-0.2.8 pytorch-lightning-1.6.5 regex-2022.7.9 requests-oauthlib-1.3.1 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tokenizers-0.12.1 torchmetrics-0.9.2 transformers-4.20.1 watermark-2.3.1 yarl-1.7.2\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2022-07-17 00:23:44,120 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2022-07-17 00:23:44,120 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2022-07-17 00:23:44,123 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-17 00:23:44,131 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-17 00:23:44,141 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-17 00:23:44,148 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 32,\n",
      "        \"epochs\": 4,\n",
      "        \"learning-rate\": 2e-05\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.c5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-07-17-00-20-36-989\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-113969896847/pytorch-training-2022-07-17-00-20-36-989/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"multibert\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"multibert.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":32,\"epochs\":4,\"learning-rate\":2e-05}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=multibert.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.c5.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=multibert\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-113969896847/pytorch-training-2022-07-17-00-20-36-989/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.c5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch-size\":32,\"epochs\":4,\"learning-rate\":2e-05},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"job_name\":\"pytorch-training-2022-07-17-00-20-36-989\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-113969896847/pytorch-training-2022-07-17-00-20-36-989/source/sourcedir.tar.gz\",\"module_name\":\"multibert\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"multibert.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"32\",\"--epochs\",\"4\",\"--learning-rate\",\"2e-05\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=4\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING-RATE=2e-05\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220701-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 multibert.py --batch-size 32 --epochs 4 --learning-rate 2e-05\u001b[0m\n",
      "\u001b[35m2022-07-17 00:23:44,548 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[35m2022-07-17 00:23:44,548 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[35m2022-07-17 00:23:44,550 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-07-17 00:23:44,559 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-07-17 00:23:44,569 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-07-17 00:23:44,576 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[35mTraining Env:\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 32,\n",
      "        \"epochs\": 4,\n",
      "        \"learning-rate\": 2e-05\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.c5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"pytorch-training-2022-07-17-00-20-36-989\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-113969896847/pytorch-training-2022-07-17-00-20-36-989/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"multibert\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"multibert.py\"\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mEnvironment variables:\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"batch-size\":32,\"epochs\":4,\"learning-rate\":2e-05}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=multibert.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_CURRENT_INSTANCE_TYPE=ml.c5.2xlarge\u001b[0m\n",
      "\u001b[35mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[35mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[35mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}}\u001b[0m\n",
      "\u001b[35mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[35mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=multibert\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-us-west-2-113969896847/pytorch-training-2022-07-17-00-20-36-989/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-2\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.c5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch-size\":32,\"epochs\":4,\"learning-rate\":2e-05},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"job_name\":\"pytorch-training-2022-07-17-00-20-36-989\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-113969896847/pytorch-training-2022-07-17-00-20-36-989/source/sourcedir.tar.gz\",\"module_name\":\"multibert\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"multibert.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--batch-size\",\"32\",\"--epochs\",\"4\",\"--learning-rate\",\"2e-05\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[35mSM_HP_BATCH-SIZE=32\u001b[0m\n",
      "\u001b[35mSM_HP_EPOCHS=4\u001b[0m\n",
      "\u001b[35mSM_HP_LEARNING-RATE=2e-05\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220701-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.8 multibert.py --batch-size 32 --epochs 4 --learning-rate 2e-05\u001b[0m\n",
      "\u001b[34mclean_data_input: dataframe:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[34m0                                  Zuko gets bitches  ...            0.0\u001b[0m\n",
      "\u001b[34m1  Zimmerman we comin for yo life bitch. http://t...  ...            0.0\u001b[0m\n",
      "\u001b[34m2  Zhou Mi was just layin on his bed and SM just ...  ...            0.0\u001b[0m\n",
      "\u001b[34m3  Zelda bitches lol @joeylattime https://t.co/Cp...  ...            0.0\u001b[0m\n",
      "\u001b[34m4         Zack still questions my love for Oreos lol  ...            0.0\u001b[0m\n",
      "\u001b[34m5    Zach Huggins tell yo bitch to leave me tf alone  ...            0.0\u001b[0m\n",
      "\u001b[34m6  Yuu Hinouchi gets fucked by two guys until she...  ...            0.0\u001b[0m\n",
      "\u001b[34m7  Yup! RT @STheMisfit Then she got AIDs and died...  ...            0.0\u001b[0m\n",
      "\u001b[34m8  Yup, I officially do not like you. You are a n...  ...            0.0\u001b[0m\n",
      "\u001b[34m9              Yup RT @Durags4Eva: Egg nog trash rap  ...            0.0\u001b[0m\n",
      "\u001b[34m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[34mclean_data_input: column: tweet\u001b[0m\n",
      "\u001b[34m/opt/ml/code/preprocessing.py:38: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dataframe[column] = dataframe[column].str.replace('[^A-Za-z0-9 ]+','')\u001b[0m\n",
      "\u001b[34mclean_data_output: return_val:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[34m0                                  Zuko gets bitches  ...            0.0\u001b[0m\n",
      "\u001b[34m1             Zimmerman we comin for yo life bitch    ...            0.0\u001b[0m\n",
      "\u001b[34m2  Zhou Mi was just layin on his bed and SM just ...  ...            0.0\u001b[0m\n",
      "\u001b[34m3                               Zelda bitches lol     ...            0.0\u001b[0m\n",
      "\u001b[34m4         Zack still questions my love for Oreos lol  ...            0.0\u001b[0m\n",
      "\u001b[34m5    Zach Huggins tell yo bitch to leave me tf alone  ...            0.0\u001b[0m\n",
      "\u001b[34m6  Yuu Hinouchi gets fucked by two guys until she...  ...            0.0\u001b[0m\n",
      "\u001b[34m7  Yup   Then she got AIDs and died   Jenny was a...  ...            0.0\u001b[0m\n",
      "\u001b[34m8  Yup I officially do not like you You are a nee...  ...            0.0\u001b[0m\n",
      "\u001b[34m9                            Yup   Egg nog trash rap  ...            0.0\u001b[0m\n",
      "\u001b[34m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[34mclean_data completed!\u001b[0m\n",
      "\u001b[34m====================================================================================================\u001b[0m\n",
      "\u001b[34mto_int_input: dataframe:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[34m0                                  Zuko gets bitches  ...            0.0\u001b[0m\n",
      "\u001b[34m1             Zimmerman we comin for yo life bitch    ...            0.0\u001b[0m\n",
      "\u001b[34m2  Zhou Mi was just layin on his bed and SM just ...  ...            0.0\u001b[0m\n",
      "\u001b[34m3                               Zelda bitches lol     ...            0.0\u001b[0m\n",
      "\u001b[34m4         Zack still questions my love for Oreos lol  ...            0.0\u001b[0m\n",
      "\u001b[34m5    Zach Huggins tell yo bitch to leave me tf alone  ...            0.0\u001b[0m\n",
      "\u001b[34m6  Yuu Hinouchi gets fucked by two guys until she...  ...            0.0\u001b[0m\n",
      "\u001b[34m7  Yup   Then she got AIDs and died   Jenny was a...  ...            0.0\u001b[0m\n",
      "\u001b[34m8  Yup I officially do not like you You are a nee...  ...            0.0\u001b[0m\n",
      "\u001b[34m9                            Yup   Egg nog trash rap  ...            0.0\u001b[0m\n",
      "\u001b[34m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[34m/opt/ml/code/preprocessing.py:76: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[34mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[34mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'general criticsm']=dataframe.loc[:,'general criticsm'].astype(int)\u001b[0m\n",
      "\u001b[34m/opt/ml/code/preprocessing.py:77: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[34mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[34mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'disability shaming']=dataframe.loc[:,'disability shaming'].astype(int)\u001b[0m\n",
      "\u001b[34m/opt/ml/code/preprocessing.py:78: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[34mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[34mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'racial prejudice']=dataframe.loc[:,'racial prejudice'].astype(int)\u001b[0m\n",
      "\u001b[34m/opt/ml/code/preprocessing.py:79: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[34mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[34mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'sexism']=dataframe.loc[:,'sexism'].astype(int)\u001b[0m\n",
      "\u001b[34m/opt/ml/code/preprocessing.py:80: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[34mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[34mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'lgbtq+ phobia']=dataframe.loc[:,'lgbtq+ phobia'].astype(int)\u001b[0m\n",
      "\u001b[34mto_int_output: dataframe:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[34m0                                  Zuko gets bitches  ...              0\u001b[0m\n",
      "\u001b[34m1             Zimmerman we comin for yo life bitch    ...              0\u001b[0m\n",
      "\u001b[34m2  Zhou Mi was just layin on his bed and SM just ...  ...              0\u001b[0m\n",
      "\u001b[34m3                               Zelda bitches lol     ...              0\u001b[0m\n",
      "\u001b[34m4         Zack still questions my love for Oreos lol  ...              0\u001b[0m\n",
      "\u001b[34m5    Zach Huggins tell yo bitch to leave me tf alone  ...              0\u001b[0m\n",
      "\u001b[34m6  Yuu Hinouchi gets fucked by two guys until she...  ...              0\u001b[0m\n",
      "\u001b[34m7  Yup   Then she got AIDs and died   Jenny was a...  ...              0\u001b[0m\n",
      "\u001b[34m8  Yup I officially do not like you You are a nee...  ...              0\u001b[0m\n",
      "\u001b[34m9                            Yup   Egg nog trash rap  ...              0\u001b[0m\n",
      "\u001b[34m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[34mto_int completed!\u001b[0m\n",
      "\u001b[34m==================================================\u001b[0m\n",
      "\u001b[34msplit_data_input: dataframe:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[34m0                                  Zuko gets bitches  ...            0.0\u001b[0m\n",
      "\u001b[34m1             Zimmerman we comin for yo life bitch    ...            0.0\u001b[0m\n",
      "\u001b[34m2  Zhou Mi was just layin on his bed and SM just ...  ...            0.0\u001b[0m\n",
      "\u001b[34m3                               Zelda bitches lol     ...            0.0\u001b[0m\n",
      "\u001b[34m4         Zack still questions my love for Oreos lol  ...            0.0\u001b[0m\n",
      "\u001b[34m5    Zach Huggins tell yo bitch to leave me tf alone  ...            0.0\u001b[0m\n",
      "\u001b[34m6  Yuu Hinouchi gets fucked by two guys until she...  ...            0.0\u001b[0m\n",
      "\u001b[34m7  Yup   Then she got AIDs and died   Jenny was a...  ...            0.0\u001b[0m\n",
      "\u001b[34m8  Yup I officially do not like you You are a nee...  ...            0.0\u001b[0m\n",
      "\u001b[34m9                            Yup   Egg nog trash rap  ...            0.0\u001b[0m\n",
      "\u001b[34m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[34msplit_data_output: train_df:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[34m12251  Just in case the day couldnt get better wifes ...  ...            0.0\u001b[0m\n",
      "\u001b[34m8576     ion ask nobody for SHIT  ever  never have a ...  ...            0.0\u001b[0m\n",
      "\u001b[34m3163   Stomach is hurting Im starving for some early ...  ...            0.0\u001b[0m\n",
      "\u001b[34m15586                   Fuck that shit Im out this bitch  ...            0.0\u001b[0m\n",
      "\u001b[34m3437   So I decided to drive to the good walmart wher...  ...            0.0\u001b[0m\n",
      "\u001b[34m15967  Erica so desperate she bragging bout flawging ...  ...            0.0\u001b[0m\n",
      "\u001b[34m11147  My name is Bryanna you can find me at  Im the ...  ...            0.0\u001b[0m\n",
      "\u001b[34m267              You got wild bitches tellin you liessss  ...            0.0\u001b[0m\n",
      "\u001b[34m24498   only when ur around me  gotta keep dat scent ...  ...            0.0\u001b[0m\n",
      "\u001b[34m14088       I have no hoes man I dont need those though   ...            0.0\u001b[0m\n",
      "\u001b[34m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[34msplit_data_output: val_df:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[34m22497    some of them bitches give you more than a virus  ...            0.0\u001b[0m\n",
      "\u001b[34m17110  Bitch just sucked my dick and tried to give me...  ...            0.0\u001b[0m\n",
      "\u001b[34m7630     stop fucking calling these legends trash Cuz...  ...            0.0\u001b[0m\n",
      "\u001b[34m9350                                        im a faggot   ...            1.0\u001b[0m\n",
      "\u001b[34m3205                     Squidward in the face ass bitch  ...            0.0\u001b[0m\n",
      "\u001b[34m1051                         Who doesnt want a bad bitch  ...            0.0\u001b[0m\n",
      "\u001b[34m12930  if someone thinks you have hoes they just sayi...  ...            0.0\u001b[0m\n",
      "\u001b[34m4123                                     Lets go Yankees  ...            0.0\u001b[0m\n",
      "\u001b[34m24406       its trash ik just wanted to fuck with Dorsey  ...            0.0\u001b[0m\n",
      "\u001b[34m3293   Somebody toss this bitch a Dasani or something...  ...            0.0\u001b[0m\n",
      "\u001b[34m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[34msplit_data completed!\u001b[0m\n",
      "\u001b[34m====================================================================================================\u001b[0m\n",
      "\u001b[34mlabel_cols_input: dataframe:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[34m12251  Just in case the day couldnt get better wifes ...  ...            0.0\u001b[0m\n",
      "\u001b[34m8576     ion ask nobody for SHIT  ever  never have a ...  ...            0.0\u001b[0m\n",
      "\u001b[34m3163   Stomach is hurting Im starving for some early ...  ...            0.0\u001b[0m\n",
      "\u001b[34m15586                   Fuck that shit Im out this bitch  ...            0.0\u001b[0m\n",
      "\u001b[34m3437   So I decided to drive to the good walmart wher...  ...            0.0\u001b[0m\n",
      "\u001b[34m15967  Erica so desperate she bragging bout flawging ...  ...            0.0\u001b[0m\n",
      "\u001b[34m11147  My name is Bryanna you can find me at  Im the ...  ...            0.0\u001b[0m\n",
      "\u001b[34m267              You got wild bitches tellin you liessss  ...            0.0\u001b[0m\n",
      "\u001b[34m24498   only when ur around me  gotta keep dat scent ...  ...            0.0\u001b[0m\n",
      "\u001b[34m14088       I have no hoes man I dont need those though   ...            0.0\u001b[0m\n",
      "\u001b[34m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[34mlabel_cols_output: ['disability shaming', 'racial prejudice', 'sexism', 'lgbtq+ phobia']\u001b[0m\n",
      "\u001b[34mlabel_cols completed!\u001b[0m\n",
      "\u001b[34m====================================================================================================\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 29.0/29.0 [00:00<00:00, 22.1kB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/208k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading:  42%|████▏     | 88.0k/208k [00:00<00:00, 705kB/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 208k/208k [00:00<00:00, 1.24MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/426k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading:  20%|██        | 86.0k/426k [00:00<00:00, 685kB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  87%|████████▋ | 372k/426k [00:00<00:00, 1.81MB/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 426k/426k [00:00<00:00, 1.85MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/570 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 570/570 [00:00<00:00, 619kB/s]\u001b[0m\n",
      "\u001b[34mcreate_tokenizer_output: tokenizer: PreTrainedTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\u001b[0m\n",
      "\u001b[34mcreate_tokenizer completed!\u001b[0m\n",
      "\u001b[34m====================================================================================================\u001b[0m\n",
      "\u001b[34mcreate_data_module_input: train_df:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[34m12251  Just in case the day couldnt get better wifes ...  ...            0.0\u001b[0m\n",
      "\u001b[34m8576     ion ask nobody for SHIT  ever  never have a ...  ...            0.0\u001b[0m\n",
      "\u001b[34m3163   Stomach is hurting Im starving for some early ...  ...            0.0\u001b[0m\n",
      "\u001b[34m15586                   Fuck that shit Im out this bitch  ...            0.0\u001b[0m\n",
      "\u001b[34m3437   So I decided to drive to the good walmart wher...  ...            0.0\u001b[0m\n",
      "\u001b[34m15967  Erica so desperate she bragging bout flawging ...  ...            0.0\u001b[0m\n",
      "\u001b[34m11147  My name is Bryanna you can find me at  Im the ...  ...            0.0\u001b[0m\n",
      "\u001b[34m267              You got wild bitches tellin you liessss  ...            0.0\u001b[0m\n",
      "\u001b[34m24498   only when ur around me  gotta keep dat scent ...  ...            0.0\u001b[0m\n",
      "\u001b[34m14088       I have no hoes man I dont need those though   ...            0.0\u001b[0m\n",
      "\u001b[34m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[34mcreate_data_module_input: val_df:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[34m22497    some of them bitches give you more than a virus  ...            0.0\u001b[0m\n",
      "\u001b[34m17110  Bitch just sucked my dick and tried to give me...  ...            0.0\u001b[0m\n",
      "\u001b[34m7630     stop fucking calling these legends trash Cuz...  ...            0.0\u001b[0m\n",
      "\u001b[34m9350                                        im a faggot   ...            1.0\u001b[0m\n",
      "\u001b[34m3205                     Squidward in the face ass bitch  ...            0.0\u001b[0m\n",
      "\u001b[34m1051                         Who doesnt want a bad bitch  ...            0.0\u001b[0m\n",
      "\u001b[34m12930  if someone thinks you have hoes they just sayi...  ...            0.0\u001b[0m\n",
      "\u001b[34m4123                                     Lets go Yankees  ...            0.0\u001b[0m\n",
      "\u001b[34m24406       its trash ik just wanted to fuck with Dorsey  ...            0.0\u001b[0m\n",
      "\u001b[34m3293   Somebody toss this bitch a Dasani or something...  ...            0.0\u001b[0m\n",
      "\u001b[34m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[34mcreate_data_module_output: data_module: <create_model.TweetsDataModule object at 0x7ff8fb6e8400>\u001b[0m\n",
      "\u001b[34mcreate_data_module completed!\u001b[0m\n",
      "\u001b[34m====================================================================================================\u001b[0m\n",
      "\u001b[34mwarmup_and_totaltraining_steps completed!\u001b[0m\n",
      "\u001b[34m====================================================================================================\u001b[0m\n",
      "\u001b[34mtrain_model_input: LABEL_COLUMNS: ['disability shaming', 'racial prejudice', 'sexism', 'lgbtq+ phobia']\u001b[0m\n",
      "\u001b[34mtrain_model_input: warmup_steps: 522\u001b[0m\n",
      "\u001b[34mtrain_model_input: total_training_steps: 2612\u001b[0m\n",
      "\u001b[34mtrain_model_input: data_module: <create_model.TweetsDataModule object at 0x7ff8fb6e8400>\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"multibert.py\", line 147, in <module>\u001b[0m\n",
      "\u001b[34mmultibert_classifier = model(train_df)\n",
      "  File \"multibert.py\", line 76, in model\n",
      "    train_model(LABEL_COLUMNS, warmup_steps, total_training_steps, data_module)\n",
      "  File \"/opt/ml/code/create_model.py\", line 260, in train_model\u001b[0m\n",
      "\u001b[34mmodel = TweetTagger(\n",
      "  File \"/opt/ml/code/create_model.py\", line 170, in __init__\u001b[0m\n",
      "\u001b[34mself.bert = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\u001b[0m\n",
      "\u001b[34mNameError: name 'BERT_MODEL_NAME' is not defined\u001b[0m\n",
      "\u001b[34m2022-07-17 00:23:52,490 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2022-07-17 00:23:52,490 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\u001b[0m\n",
      "\u001b[34m2022-07-17 00:23:52,491 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2022-07-17 00:23:52,491 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"NameError: name 'BERT_MODEL_NAME' is not defined\u001b[0m\n",
      "\u001b[34m\"\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python3.8 multibert.py --batch-size 32 --epochs 4 --learning-rate 2e-05\"\u001b[0m\n",
      "\u001b[34m2022-07-17 00:23:52,491 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\u001b[35mclean_data_input: dataframe:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[35m0                                  Zuko gets bitches  ...            0.0\u001b[0m\n",
      "\u001b[35m1  Zimmerman we comin for yo life bitch. http://t...  ...            0.0\u001b[0m\n",
      "\u001b[35m2  Zhou Mi was just layin on his bed and SM just ...  ...            0.0\u001b[0m\n",
      "\u001b[35m3  Zelda bitches lol @joeylattime https://t.co/Cp...  ...            0.0\u001b[0m\n",
      "\u001b[35m4         Zack still questions my love for Oreos lol  ...            0.0\u001b[0m\n",
      "\u001b[35m5    Zach Huggins tell yo bitch to leave me tf alone  ...            0.0\u001b[0m\n",
      "\u001b[35m6  Yuu Hinouchi gets fucked by two guys until she...  ...            0.0\u001b[0m\n",
      "\u001b[35m7  Yup! RT @STheMisfit Then she got AIDs and died...  ...            0.0\u001b[0m\n",
      "\u001b[35m8  Yup, I officially do not like you. You are a n...  ...            0.0\u001b[0m\n",
      "\u001b[35m9              Yup RT @Durags4Eva: Egg nog trash rap  ...            0.0\u001b[0m\n",
      "\u001b[35m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[35mclean_data_input: column: tweet\u001b[0m\n",
      "\u001b[35m/opt/ml/code/preprocessing.py:38: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dataframe[column] = dataframe[column].str.replace('[^A-Za-z0-9 ]+','')\u001b[0m\n",
      "\u001b[35mclean_data_output: return_val:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[35m0                                  Zuko gets bitches  ...            0.0\u001b[0m\n",
      "\u001b[35m1             Zimmerman we comin for yo life bitch    ...            0.0\u001b[0m\n",
      "\u001b[35m2  Zhou Mi was just layin on his bed and SM just ...  ...            0.0\u001b[0m\n",
      "\u001b[35m3                               Zelda bitches lol     ...            0.0\u001b[0m\n",
      "\u001b[35m4         Zack still questions my love for Oreos lol  ...            0.0\u001b[0m\n",
      "\u001b[35m5    Zach Huggins tell yo bitch to leave me tf alone  ...            0.0\u001b[0m\n",
      "\u001b[35m6  Yuu Hinouchi gets fucked by two guys until she...  ...            0.0\u001b[0m\n",
      "\u001b[35m7  Yup   Then she got AIDs and died   Jenny was a...  ...            0.0\u001b[0m\n",
      "\u001b[35m8  Yup I officially do not like you You are a nee...  ...            0.0\u001b[0m\n",
      "\u001b[35m9                            Yup   Egg nog trash rap  ...            0.0\u001b[0m\n",
      "\u001b[35m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[35mclean_data completed!\u001b[0m\n",
      "\u001b[35m====================================================================================================\u001b[0m\n",
      "\u001b[35mto_int_input: dataframe:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[35m0                                  Zuko gets bitches  ...            0.0\u001b[0m\n",
      "\u001b[35m1             Zimmerman we comin for yo life bitch    ...            0.0\u001b[0m\n",
      "\u001b[35m2  Zhou Mi was just layin on his bed and SM just ...  ...            0.0\u001b[0m\n",
      "\u001b[35m3                               Zelda bitches lol     ...            0.0\u001b[0m\n",
      "\u001b[35m4         Zack still questions my love for Oreos lol  ...            0.0\u001b[0m\n",
      "\u001b[35m5    Zach Huggins tell yo bitch to leave me tf alone  ...            0.0\u001b[0m\n",
      "\u001b[35m6  Yuu Hinouchi gets fucked by two guys until she...  ...            0.0\u001b[0m\n",
      "\u001b[35m7  Yup   Then she got AIDs and died   Jenny was a...  ...            0.0\u001b[0m\n",
      "\u001b[35m8  Yup I officially do not like you You are a nee...  ...            0.0\u001b[0m\n",
      "\u001b[35m9                            Yup   Egg nog trash rap  ...            0.0\u001b[0m\n",
      "\u001b[35m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[35m/opt/ml/code/preprocessing.py:76: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[35mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[35mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[35mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'general criticsm']=dataframe.loc[:,'general criticsm'].astype(int)\u001b[0m\n",
      "\u001b[35m/opt/ml/code/preprocessing.py:77: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[35mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[35mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[35mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'disability shaming']=dataframe.loc[:,'disability shaming'].astype(int)\u001b[0m\n",
      "\u001b[35m/opt/ml/code/preprocessing.py:78: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[35mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[35mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[35mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'racial prejudice']=dataframe.loc[:,'racial prejudice'].astype(int)\u001b[0m\n",
      "\u001b[35m/opt/ml/code/preprocessing.py:79: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[35mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[35mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[35mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'sexism']=dataframe.loc[:,'sexism'].astype(int)\u001b[0m\n",
      "\u001b[35m/opt/ml/code/preprocessing.py:80: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[35mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[35mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[35mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'lgbtq+ phobia']=dataframe.loc[:,'lgbtq+ phobia'].astype(int)\u001b[0m\n",
      "\u001b[35mto_int_output: dataframe:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[35m0                                  Zuko gets bitches  ...              0\u001b[0m\n",
      "\u001b[35m1             Zimmerman we comin for yo life bitch    ...              0\u001b[0m\n",
      "\u001b[35m2  Zhou Mi was just layin on his bed and SM just ...  ...              0\u001b[0m\n",
      "\u001b[35m3                               Zelda bitches lol     ...              0\u001b[0m\n",
      "\u001b[35m4         Zack still questions my love for Oreos lol  ...              0\u001b[0m\n",
      "\u001b[35m5    Zach Huggins tell yo bitch to leave me tf alone  ...              0\u001b[0m\n",
      "\u001b[35m6  Yuu Hinouchi gets fucked by two guys until she...  ...              0\u001b[0m\n",
      "\u001b[35m7  Yup   Then she got AIDs and died   Jenny was a...  ...              0\u001b[0m\n",
      "\u001b[35m8  Yup I officially do not like you You are a nee...  ...              0\u001b[0m\n",
      "\u001b[35m9                            Yup   Egg nog trash rap  ...              0\u001b[0m\n",
      "\u001b[35m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[35mto_int completed!\u001b[0m\n",
      "\u001b[35m==================================================\u001b[0m\n",
      "\u001b[35msplit_data_input: dataframe:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[35m0                                  Zuko gets bitches  ...            0.0\u001b[0m\n",
      "\u001b[35m1             Zimmerman we comin for yo life bitch    ...            0.0\u001b[0m\n",
      "\u001b[35m2  Zhou Mi was just layin on his bed and SM just ...  ...            0.0\u001b[0m\n",
      "\u001b[35m3                               Zelda bitches lol     ...            0.0\u001b[0m\n",
      "\u001b[35m4         Zack still questions my love for Oreos lol  ...            0.0\u001b[0m\n",
      "\u001b[35m5    Zach Huggins tell yo bitch to leave me tf alone  ...            0.0\u001b[0m\n",
      "\u001b[35m6  Yuu Hinouchi gets fucked by two guys until she...  ...            0.0\u001b[0m\n",
      "\u001b[35m7  Yup   Then she got AIDs and died   Jenny was a...  ...            0.0\u001b[0m\n",
      "\u001b[35m8  Yup I officially do not like you You are a nee...  ...            0.0\u001b[0m\n",
      "\u001b[35m9                            Yup   Egg nog trash rap  ...            0.0\u001b[0m\n",
      "\u001b[35m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[35msplit_data_output: train_df:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[35m11236                             My dad is such a bitch  ...            0.0\u001b[0m\n",
      "\u001b[35m15637                   Fuck all u stupid hoes idgafmode  ...            0.0\u001b[0m\n",
      "\u001b[35m21278   lmao im bein foreal fuck all them bitches lik...  ...            0.0\u001b[0m\n",
      "\u001b[35m21394   just got his pussy kicked hes out done  wins ...  ...            0.0\u001b[0m\n",
      "\u001b[35m2608                          them bitches are good lmao  ...            0.0\u001b[0m\n",
      "\u001b[35m2375   These smoking commercials be blowing me Like b...  ...            0.0\u001b[0m\n",
      "\u001b[35m11676                     Lol  Ooop QT  You little twats  ...            0.0\u001b[0m\n",
      "\u001b[35m7785     Pop a molly Why dont some of you hoes start ...  ...            0.0\u001b[0m\n",
      "\u001b[35m23575                                    ok Stupid bitch  ...            0.0\u001b[0m\n",
      "\u001b[35m11789  LMFAO  I found my diary me complaining about y...  ...            0.0\u001b[0m\n",
      "\u001b[35m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[35msplit_data_output: val_df:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[35m12011  Lets be serious Most fanscallers wanted to run...  ...            0.0\u001b[0m\n",
      "\u001b[35m11314  Musta let dem retards out to food shop One jus...  ...            0.0\u001b[0m\n",
      "\u001b[35m19190      Still cant see what niggers see in them wh...  ...            0.0\u001b[0m\n",
      "\u001b[35m1482   We bout to be the next Chik Fil A lmao Couple ...  ...            1.0\u001b[0m\n",
      "\u001b[35m10444  One thing I love about russel Wilson he aint a...  ...            0.0\u001b[0m\n",
      "\u001b[35m3148                             Stop Twatching me bitch  ...            0.0\u001b[0m\n",
      "\u001b[35m13332                      Im a sucker for colored eyes   ...            0.0\u001b[0m\n",
      "\u001b[35m22054   gross ill stick with my galaxy it will still ...  ...            0.0\u001b[0m\n",
      "\u001b[35m9310     When that message say but you see him postin...  ...            0.0\u001b[0m\n",
      "\u001b[35m11974                    Lifes a bitch then you die Tony  ...            0.0\u001b[0m\n",
      "\u001b[35m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[35msplit_data completed!\u001b[0m\n",
      "\u001b[35m====================================================================================================\u001b[0m\n",
      "\u001b[35mlabel_cols_input: dataframe:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[35m11236                             My dad is such a bitch  ...            0.0\u001b[0m\n",
      "\u001b[35m15637                   Fuck all u stupid hoes idgafmode  ...            0.0\u001b[0m\n",
      "\u001b[35m21278   lmao im bein foreal fuck all them bitches lik...  ...            0.0\u001b[0m\n",
      "\u001b[35m21394   just got his pussy kicked hes out done  wins ...  ...            0.0\u001b[0m\n",
      "\u001b[35m2608                          them bitches are good lmao  ...            0.0\u001b[0m\n",
      "\u001b[35m2375   These smoking commercials be blowing me Like b...  ...            0.0\u001b[0m\n",
      "\u001b[35m11676                     Lol  Ooop QT  You little twats  ...            0.0\u001b[0m\n",
      "\u001b[35m7785     Pop a molly Why dont some of you hoes start ...  ...            0.0\u001b[0m\n",
      "\u001b[35m23575                                    ok Stupid bitch  ...            0.0\u001b[0m\n",
      "\u001b[35m11789  LMFAO  I found my diary me complaining about y...  ...            0.0\u001b[0m\n",
      "\u001b[35m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[35mlabel_cols_output: ['disability shaming', 'racial prejudice', 'sexism', 'lgbtq+ phobia']\u001b[0m\n",
      "\u001b[35mlabel_cols completed!\u001b[0m\n",
      "\u001b[35m====================================================================================================\u001b[0m\n",
      "\u001b[35mDownloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35mDownloading: 100%|██████████| 29.0/29.0 [00:00<00:00, 32.0kB/s]\u001b[0m\n",
      "\u001b[35mDownloading:   0%|          | 0.00/208k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35mDownloading:  38%|███▊      | 80.0k/208k [00:00<00:00, 752kB/s]\u001b[0m\n",
      "\u001b[35mDownloading: 100%|██████████| 208k/208k [00:00<00:00, 1.03MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:   0%|          | 0.00/426k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35mDownloading:   7%|▋         | 28.0k/426k [00:00<00:01, 227kB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  47%|████▋     | 201k/426k [00:00<00:00, 915kB/s]\u001b[0m\n",
      "\u001b[35mDownloading: 100%|██████████| 426k/426k [00:00<00:00, 1.47MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:   0%|          | 0.00/570 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35mDownloading: 100%|██████████| 570/570 [00:00<00:00, 592kB/s]\u001b[0m\n",
      "\u001b[35mcreate_tokenizer_output: tokenizer: PreTrainedTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\u001b[0m\n",
      "\u001b[35mcreate_tokenizer completed!\u001b[0m\n",
      "\u001b[35m====================================================================================================\u001b[0m\n",
      "\u001b[35mcreate_data_module_input: train_df:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[35m11236                             My dad is such a bitch  ...            0.0\u001b[0m\n",
      "\u001b[35m15637                   Fuck all u stupid hoes idgafmode  ...            0.0\u001b[0m\n",
      "\u001b[35m21278   lmao im bein foreal fuck all them bitches lik...  ...            0.0\u001b[0m\n",
      "\u001b[35m21394   just got his pussy kicked hes out done  wins ...  ...            0.0\u001b[0m\n",
      "\u001b[35m2608                          them bitches are good lmao  ...            0.0\u001b[0m\n",
      "\u001b[35m2375   These smoking commercials be blowing me Like b...  ...            0.0\u001b[0m\n",
      "\u001b[35m11676                     Lol  Ooop QT  You little twats  ...            0.0\u001b[0m\n",
      "\u001b[35m7785     Pop a molly Why dont some of you hoes start ...  ...            0.0\u001b[0m\n",
      "\u001b[35m23575                                    ok Stupid bitch  ...            0.0\u001b[0m\n",
      "\u001b[35m11789  LMFAO  I found my diary me complaining about y...  ...            0.0\u001b[0m\n",
      "\u001b[35m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[35mcreate_data_module_input: val_df:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[35m12011  Lets be serious Most fanscallers wanted to run...  ...            0.0\u001b[0m\n",
      "\u001b[35m11314  Musta let dem retards out to food shop One jus...  ...            0.0\u001b[0m\n",
      "\u001b[35m19190      Still cant see what niggers see in them wh...  ...            0.0\u001b[0m\n",
      "\u001b[35m1482   We bout to be the next Chik Fil A lmao Couple ...  ...            1.0\u001b[0m\n",
      "\u001b[35m10444  One thing I love about russel Wilson he aint a...  ...            0.0\u001b[0m\n",
      "\u001b[35m3148                             Stop Twatching me bitch  ...            0.0\u001b[0m\n",
      "\u001b[35m13332                      Im a sucker for colored eyes   ...            0.0\u001b[0m\n",
      "\u001b[35m22054   gross ill stick with my galaxy it will still ...  ...            0.0\u001b[0m\n",
      "\u001b[35m9310     When that message say but you see him postin...  ...            0.0\u001b[0m\n",
      "\u001b[35m11974                    Lifes a bitch then you die Tony  ...            0.0\u001b[0m\n",
      "\u001b[35m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[35mcreate_data_module_output: data_module: <create_model.TweetsDataModule object at 0x7f22458bbc10>\u001b[0m\n",
      "\u001b[35mcreate_data_module completed!\u001b[0m\n",
      "\u001b[35m====================================================================================================\u001b[0m\n",
      "\u001b[35mwarmup_and_totaltraining_steps completed!\u001b[0m\n",
      "\u001b[35m====================================================================================================\u001b[0m\n",
      "\u001b[35mtrain_model_input: LABEL_COLUMNS: ['disability shaming', 'racial prejudice', 'sexism', 'lgbtq+ phobia']\u001b[0m\n",
      "\u001b[35mtrain_model_input: warmup_steps: 522\u001b[0m\n",
      "\u001b[35mtrain_model_input: total_training_steps: 2612\u001b[0m\n",
      "\u001b[35mtrain_model_input: data_module: <create_model.TweetsDataModule object at 0x7f22458bbc10>\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"multibert.py\", line 147, in <module>\u001b[0m\n",
      "\u001b[35mmultibert_classifier = model(train_df)\n",
      "  File \"multibert.py\", line 76, in model\n",
      "    train_model(LABEL_COLUMNS, warmup_steps, total_training_steps, data_module)\n",
      "  File \"/opt/ml/code/create_model.py\", line 260, in train_model\u001b[0m\n",
      "\u001b[35mmodel = TweetTagger(\n",
      "  File \"/opt/ml/code/create_model.py\", line 170, in __init__\n",
      "    self.bert = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\u001b[0m\n",
      "\u001b[35mNameError: name 'BERT_MODEL_NAME' is not defined\u001b[0m\n",
      "\u001b[35m2022-07-17 00:23:53,597 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[35m2022-07-17 00:23:53,597 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\u001b[0m\n",
      "\u001b[35m2022-07-17 00:23:53,598 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[35m2022-07-17 00:23:53,598 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[35mExitCode 1\u001b[0m\n",
      "\u001b[35mErrorMessage \"NameError: name 'BERT_MODEL_NAME' is not defined\u001b[0m\n",
      "\u001b[35m\"\u001b[0m\n",
      "\u001b[35mCommand \"/opt/conda/bin/python3.8 multibert.py --batch-size 32 --epochs 4 --learning-rate 2e-05\"\u001b[0m\n",
      "\u001b[35m2022-07-17 00:23:53,598 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\n",
      "2022-07-17 00:24:23 Uploading - Uploading generated training model\n",
      "2022-07-17 00:24:23 Failed - Training job failed\n",
      "ProfilerReport-1658017238: Stopping\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job pytorch-training-2022-07-17-00-20-36-989: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"NameError: name 'BERT_MODEL_NAME' is not defined\n\"\nCommand \"/opt/conda/bin/python3.8 multibert.py --batch-size 32 --epochs 4 --learning-rate 2e-05\", exit code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q_/glkcp8_n5h300xwrkqscmh9c0000gn/T/ipykernel_26108/4232306621.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# cell 07\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpytorch_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#pytorch_estimator.fit({'train': training_data_uri,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#                       'test': test_data_uri})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2080\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2082\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2083\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3851\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3852\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3853\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3387\u001b[0m                     \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3388\u001b[0m                 )\n\u001b[0;32m-> 3389\u001b[0;31m             raise exceptions.UnexpectedStatusException(\n\u001b[0m\u001b[1;32m   3390\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job pytorch-training-2022-07-17-00-20-36-989: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"NameError: name 'BERT_MODEL_NAME' is not defined\n\"\nCommand \"/opt/conda/bin/python3.8 multibert.py --batch-size 32 --epochs 4 --learning-rate 2e-05\", exit code: 1"
     ]
    }
   ],
   "source": [
    "# cell 07\n",
    "pytorch_estimator.fit(training_data_uri)\n",
    "#pytorch_estimator.fit({'train': training_data_uri,\n",
    "#                       'test': test_data_uri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 09\n",
    "predictor = pytorch_estimator.deploy(instance_type='ml.m4.xlarge',\n",
    "                                     initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 11\n",
    "data = \"I am a test.\"\n",
    "response = predictor.predict(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
