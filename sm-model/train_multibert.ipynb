{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (1.24.30)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.30 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from boto3) (1.27.30)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from boto3) (0.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.30->boto3) (1.26.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.30->boto3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.30->boto3) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sagemaker in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (2.99.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: google-pasta in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (4.8.1)\n",
      "Requirement already satisfied: boto3<2.0,>=1.20.21 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (1.24.30)\n",
      "Requirement already satisfied: attrs<22,>=20.3.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (21.2.0)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (21.0)\n",
      "Requirement already satisfied: pathos in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (0.2.9)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (3.18.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (1.20.3)\n",
      "Requirement already satisfied: pandas in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (1.3.2)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.30 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (1.27.30)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.30->boto3<2.0,>=1.20.21->sagemaker) (1.26.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.30->boto3<2.0,>=1.20.21->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->sagemaker) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from pandas->sagemaker) (2021.1)\n",
      "Requirement already satisfied: pox>=0.3.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.1)\n",
      "Requirement already satisfied: dill>=0.3.5.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.5.1)\n",
      "Requirement already satisfied: multiprocess>=0.70.13 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from pathos->sagemaker) (0.70.13)\n",
      "Requirement already satisfied: ppft>=1.7.6.5 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from pathos->sagemaker) (1.7.6.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sagemaker in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (2.99.0)\n",
      "Requirement already satisfied: google-pasta in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: attrs<22,>=20.3.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (21.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (1.20.3)\n",
      "Requirement already satisfied: boto3<2.0,>=1.20.21 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (1.24.30)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (21.0)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (4.8.1)\n",
      "Requirement already satisfied: pathos in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (0.2.9)\n",
      "Requirement already satisfied: pandas in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (1.3.2)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (3.18.0)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.30 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (1.27.30)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.30->boto3<2.0,>=1.20.21->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.30->boto3<2.0,>=1.20.21->sagemaker) (1.26.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->sagemaker) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from pandas->sagemaker) (2021.1)\n",
      "Requirement already satisfied: multiprocess>=0.70.13 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from pathos->sagemaker) (0.70.13)\n",
      "Requirement already satisfied: ppft>=1.7.6.5 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from pathos->sagemaker) (1.7.6.5)\n",
      "Requirement already satisfied: dill>=0.3.5.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.5.1)\n",
      "Requirement already satisfied: pox>=0.3.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchmetrics in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (0.9.2)\n",
      "Requirement already satisfied: packaging in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from torchmetrics) (21.0)\n",
      "Requirement already satisfied: torch>=1.3.1 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from torchmetrics) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from torchmetrics) (1.20.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from torch>=1.3.1->torchmetrics) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/evanphillips/opt/anaconda3/lib/python3.8/site-packages (from packaging->torchmetrics) (2.4.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install packages\n",
    "%pip install boto3\n",
    "%pip install sagemaker\n",
    "%pip install -U sagemaker\n",
    "%pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 01\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import sagemaker\n",
    "import torchmetrics\n",
    "import torch\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = 'AmazonSageMaker-ExecutionRole-20220714T204241'\n",
    "# role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 02\n",
    "training_data_uri = 's3://multibert-8b87f872-a3fe-4a19-a016-e02402275450/training/multi_label_new.csv'\n",
    "#test_data_uri = 's3://multibert-8b87f872-a3fe-4a19-a016-e02402275450/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 05\n",
    "pytorch_estimator = PyTorch('multibert.py',\n",
    "                            instance_type='ml.g4dn.16xlarge',\n",
    "                            instance_count=3,\n",
    "                            role = role,\n",
    "                            framework_version='1.11.0',\n",
    "                            py_version='py38',\n",
    "                            source_dir = 'code',\n",
    "                            hyperparameters = {'epochs': 4, 'batch-size': 32, 'learning-rate': 2e-05})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-18 19:16:22 Starting - Starting the training job...\n",
      "2022-07-18 19:16:46 Starting - Preparing the instances for trainingProfilerReport-1658171781: InProgress\n",
      ".........\n",
      "2022-07-18 19:18:26 Downloading - Downloading input data\n",
      "2022-07-18 19:18:26 Training - Downloading the training image..................\n",
      "2022-07-18 19:21:29 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-07-18 19:21:32,896 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-07-18 19:21:32,915 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-07-18 19:21:32,920 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-07-18 19:21:33,333 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35m2022-07-18 19:21:32,895 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2022-07-18 19:21:32,914 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2022-07-18 19:21:32,920 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2022-07-18 19:21:33,324 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.11.0+cu113)\u001b[0m\n",
      "\u001b[32mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[32mbash: no job control in this shell\u001b[0m\n",
      "\u001b[32m2022-07-18 19:21:33,149 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[32m2022-07-18 19:21:33,167 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[32m2022-07-18 19:21:33,173 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[32m2022-07-18 19:21:33,585 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[32m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.11.0+cu113)\u001b[0m\n",
      "\u001b[32mCollecting watermark\u001b[0m\n",
      "\u001b[32mDownloading watermark-2.3.1-py2.py3-none-any.whl (7.2 kB)\u001b[0m\n",
      "\u001b[32mCollecting transformers\u001b[0m\n",
      "\u001b[32mDownloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.11.0+cu113)\u001b[0m\n",
      "\u001b[34mCollecting watermark\u001b[0m\n",
      "\u001b[34mDownloading watermark-2.3.1-py2.py3-none-any.whl (7.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting transformers\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.4/4.4 MB 53.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pytorch-lightning\u001b[0m\n",
      "\u001b[34mDownloading pytorch_lightning-1.6.5-py3-none-any.whl (585 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 585.9/585.9 kB 56.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting colored\u001b[0m\n",
      "\u001b[34mDownloading colored-1.4.3.tar.gz (29 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[35mCollecting watermark\u001b[0m\n",
      "\u001b[35mDownloading watermark-2.3.1-py2.py3-none-any.whl (7.2 kB)\u001b[0m\n",
      "\u001b[35mCollecting transformers\u001b[0m\n",
      "\u001b[35mDownloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.4/4.4 MB 48.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting pytorch-lightning\u001b[0m\n",
      "\u001b[35mDownloading pytorch_lightning-1.6.5-py3-none-any.whl (585 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 585.9/585.9 kB 60.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting colored\u001b[0m\n",
      "\u001b[35mDownloading colored-1.4.3.tar.gz (29 kB)\u001b[0m\n",
      "\u001b[35mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[35mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mCollecting torchmetrics\u001b[0m\n",
      "\u001b[35mDownloading torchmetrics-0.9.2-py3-none-any.whl (419 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 419.7/419.7 kB 46.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch->-r requirements.txt (line 1)) (4.3.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: ipython in /opt/conda/lib/python3.8/site-packages (from watermark->-r requirements.txt (line 2)) (8.1.0)\u001b[0m\n",
      "\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.4/4.4 MB 53.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mCollecting pytorch-lightning\u001b[0m\n",
      "\u001b[32mDownloading pytorch_lightning-1.6.5-py3-none-any.whl (585 kB)\u001b[0m\n",
      "\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 585.9/585.9 kB 54.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mCollecting colored\u001b[0m\n",
      "\u001b[32mDownloading colored-1.4.3.tar.gz (29 kB)\u001b[0m\n",
      "\u001b[32mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[32mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[32mCollecting torchmetrics\u001b[0m\n",
      "\u001b[32mDownloading torchmetrics-0.9.2-py3-none-any.whl (419 kB)\u001b[0m\n",
      "\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 419.7/419.7 kB 42.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch->-r requirements.txt (line 1)) (4.3.0)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: ipython in /opt/conda/lib/python3.8/site-packages (from watermark->-r requirements.txt (line 2)) (8.1.0)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (5.4.1)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (1.22.2)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (21.3)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (2.28.1)\u001b[0m\n",
      "\u001b[32mCollecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[32mDownloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\u001b[0m\n",
      "\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.5/101.5 kB 10.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting torchmetrics\u001b[0m\n",
      "\u001b[34mDownloading torchmetrics-0.9.2-py3-none-any.whl (419 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 419.7/419.7 kB 44.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch->-r requirements.txt (line 1)) (4.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ipython in /opt/conda/lib/python3.8/site-packages (from watermark->-r requirements.txt (line 2)) (8.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (2.28.1)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 101.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (4.64.0)\u001b[0m\n",
      "\u001b[34mCollecting filelock\u001b[0m\n",
      "\u001b[34mDownloading filelock-3.7.1-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (21.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (1.22.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (4.64.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (2.28.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (5.4.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (21.3)\u001b[0m\n",
      "\u001b[35mCollecting filelock\u001b[0m\n",
      "\u001b[35mDownloading filelock-3.7.1-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (1.22.2)\u001b[0m\n",
      "\u001b[35mCollecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[35mDownloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.5/101.5 kB 9.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[35mDownloading regex-2022.7.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (765 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 765.0/765.0 kB 48.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[32mDownloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 105.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mCollecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[32mDownloading regex-2022.7.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (765 kB)\u001b[0m\n",
      "\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 765.0/765.0 kB 68.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mCollecting filelock\u001b[0m\n",
      "\u001b[32mDownloading filelock-3.7.1-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 3)) (4.64.0)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[34mDownloading regex-2022.7.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (765 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 765.0/765.0 kB 67.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.5/101.5 kB 26.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pyDeprecate>=0.3.1\u001b[0m\n",
      "\u001b[34mDownloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<=3.20.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 4)) (3.19.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 4)) (2022.5.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard>=2.2.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.8/5.8 MB 107.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[35mDownloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 105.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: protobuf<=3.20.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 4)) (3.19.4)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 4)) (2022.5.0)\u001b[0m\n",
      "\u001b[35mCollecting pyDeprecate>=0.3.1\u001b[0m\n",
      "\u001b[35mDownloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35mCollecting tensorboard>=2.2.0\u001b[0m\n",
      "\u001b[35mDownloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.8/5.8 MB 102.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting aiohttp\u001b[0m\n",
      "\u001b[35mDownloading aiohttp-3.8.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 87.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mCollecting tensorboard>=2.2.0\u001b[0m\n",
      "\u001b[32mDownloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\u001b[0m\n",
      "\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.8/5.8 MB 103.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mCollecting pyDeprecate>=0.3.1\u001b[0m\n",
      "\u001b[32mDownloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 4)) (2022.5.0)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: protobuf<=3.20.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning->-r requirements.txt (line 4)) (3.19.4)\u001b[0m\n",
      "\u001b[32mCollecting aiohttp\u001b[0m\n",
      "\u001b[32mDownloading aiohttp-3.8.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 84.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers->-r requirements.txt (line 3)) (3.0.9)\u001b[0m\n",
      "\u001b[32mCollecting absl-py>=0.4\u001b[0m\n",
      "\u001b[32mDownloading absl_py-1.1.0-py3-none-any.whl (123 kB)\u001b[0m\n",
      "\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.7/123.7 kB 11.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (2.1.2)\u001b[0m\n",
      "\u001b[32mCollecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[32mDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (63.2.0)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (0.37.1)\u001b[0m\n",
      "\u001b[32mCollecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[32mDownloading google_auth-2.9.1-py2.py3-none-any.whl (167 kB)\u001b[0m\n",
      "\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 167.8/167.8 kB 38.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting aiohttp\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.8.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 81.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers->-r requirements.txt (line 3)) (3.0.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (0.37.1)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34mDownloading google_auth-2.9.1-py2.py3-none-any.whl (167 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 167.8/167.8 kB 37.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (2.1.2)\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34mDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34mDownloading absl_py-1.1.0-py3-none-any.whl (123 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.7/123.7 kB 25.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 66.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 101.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers->-r requirements.txt (line 3)) (3.0.9)\u001b[0m\n",
      "\u001b[35mCollecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[35mDownloading Markdown-3.4.1-py3-none-any.whl (93 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.3/93.3 kB 24.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting absl-py>=0.4\u001b[0m\n",
      "\u001b[35mDownloading absl_py-1.1.0-py3-none-any.whl (123 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.7/123.7 kB 29.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[35mDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[35mCollecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[35mDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 35.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[35mDownloading google_auth-2.9.1-py2.py3-none-any.whl (167 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 167.8/167.8 kB 10.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mCollecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[32mDownloading Markdown-3.4.1-py3-none-any.whl (93 kB)\u001b[0m\n",
      "\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.3/93.3 kB 23.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mCollecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[32mDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 41.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mCollecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[32mDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 113.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mCollecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[32mDownloading grpcio-1.47.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\u001b[0m\n",
      "\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 123.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 3)) (2.1.0)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 3)) (3.3)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 3)) (1.26.10)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 3)) (2022.6.15)\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[34mDownloading grpcio-1.47.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 114.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34mDownloading Markdown-3.4.1-py3-none-any.whl (93 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.3/93.3 kB 9.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (63.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 3)) (1.26.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 3)) (2022.6.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 3)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 3)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.18.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (2.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (4.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (3.0.30)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.7.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: stack-data in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (5.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (5.3.0)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34mDownloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 16.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34mDownloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (4.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34mDownloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython->watermark->-r requirements.txt (line 2)) (0.8.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (4.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython->watermark->-r requirements.txt (line 2)) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->watermark->-r requirements.txt (line 2)) (0.2.5)\u001b[0m\n",
      "\u001b[35mCollecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[35mDownloading grpcio-1.47.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 75.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (63.2.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (2.1.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (0.37.1)\u001b[0m\n",
      "\u001b[35mCollecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[35mDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 115.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 3)) (2.1.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 3)) (3.3)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 3)) (1.26.10)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 3)) (2022.6.15)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.2.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (2.12.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (5.3.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (3.0.30)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.7.5)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.1.3)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: stack-data in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.3.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (5.1.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (4.8.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.18.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (1.16.0)\u001b[0m\n",
      "\u001b[35mCollecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[35mDownloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 14.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[35mDownloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (4.7.2)\u001b[0m\n",
      "\u001b[35mCollecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[35mDownloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython->watermark->-r requirements.txt (line 2)) (0.8.3)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (4.12.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython->watermark->-r requirements.txt (line 2)) (0.7.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->watermark->-r requirements.txt (line 2)) (0.2.5)\u001b[0m\n",
      "\u001b[35mCollecting frozenlist>=1.1.1\u001b[0m\n",
      "\u001b[35mDownloading frozenlist-1.3.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 158.7/158.7 kB 36.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (2.12.0)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: stack-data in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.3.0)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (4.8.0)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (5.1.1)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.18.1)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (3.0.30)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.2.0)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.1.3)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (0.7.5)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.8/site-packages (from ipython->watermark->-r requirements.txt (line 2)) (5.3.0)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (4.7.2)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (1.16.0)\u001b[0m\n",
      "\u001b[32mCollecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[32mDownloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\u001b[0m\n",
      "\u001b[32mCollecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[32mDownloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 16.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mCollecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[32mDownloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython->watermark->-r requirements.txt (line 2)) (0.8.3)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (4.12.0)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython->watermark->-r requirements.txt (line 2)) (0.7.0)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->watermark->-r requirements.txt (line 2)) (0.2.5)\u001b[0m\n",
      "\u001b[32mCollecting yarl<2.0,>=1.0\u001b[0m\n",
      "\u001b[32mDownloading yarl-1.7.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (308 kB)\u001b[0m\n",
      "\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 308.6/308.6 kB 43.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mCollecting async-timeout<5.0,>=4.0.0a3\u001b[0m\n",
      "\u001b[32mDownloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\u001b[0m\n",
      "\u001b[32mCollecting frozenlist>=1.1.1\u001b[0m\n",
      "\u001b[32mDownloading frozenlist-1.3.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\u001b[0m\n",
      "\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 158.7/158.7 kB 26.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 4)) (21.4.0)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.7.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (308 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 308.6/308.6 kB 31.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.3/121.3 kB 30.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<5.0,>=4.0.0a3\u001b[0m\n",
      "\u001b[34mDownloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 4)) (21.4.0)\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.3.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 158.7/158.7 kB 23.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.1.2\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pure-eval in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->watermark->-r requirements.txt (line 2)) (0.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: asttokens in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->watermark->-r requirements.txt (line 2)) (2.0.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: executing in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->watermark->-r requirements.txt (line 2)) (0.8.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (3.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (0.4.8)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34mDownloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.5/151.5 kB 32.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: colored\u001b[0m\n",
      "\u001b[34mBuilding wheel for colored (setup.py): started\u001b[0m\n",
      "\u001b[35mCollecting multidict<7.0,>=4.5\u001b[0m\n",
      "\u001b[35mDownloading multidict-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.3/121.3 kB 25.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting yarl<2.0,>=1.0\u001b[0m\n",
      "\u001b[35mDownloading yarl-1.7.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (308 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 308.6/308.6 kB 22.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 4)) (21.4.0)\u001b[0m\n",
      "\u001b[35mCollecting async-timeout<5.0,>=4.0.0a3\u001b[0m\n",
      "\u001b[35mDownloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\u001b[0m\n",
      "\u001b[35mCollecting aiosignal>=1.1.2\u001b[0m\n",
      "\u001b[35mDownloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: asttokens in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->watermark->-r requirements.txt (line 2)) (2.0.5)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: executing in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->watermark->-r requirements.txt (line 2)) (0.8.3)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pure-eval in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->watermark->-r requirements.txt (line 2)) (0.2.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (3.8.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (0.4.8)\u001b[0m\n",
      "\u001b[35mCollecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[35mDownloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.5/151.5 kB 22.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: colored\u001b[0m\n",
      "\u001b[35mBuilding wheel for colored (setup.py): started\u001b[0m\n",
      "\u001b[32mCollecting multidict<7.0,>=4.5\u001b[0m\n",
      "\u001b[32mDownloading multidict-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\u001b[0m\n",
      "\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.3/121.3 kB 28.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mCollecting aiosignal>=1.1.2\u001b[0m\n",
      "\u001b[32mDownloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: pure-eval in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->watermark->-r requirements.txt (line 2)) (0.2.2)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: executing in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->watermark->-r requirements.txt (line 2)) (0.8.3)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: asttokens in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->watermark->-r requirements.txt (line 2)) (2.0.5)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (3.8.1)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 4)) (0.4.8)\u001b[0m\n",
      "\u001b[32mCollecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[32mDownloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.5/151.5 kB 24.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[32mBuilding wheels for collected packages: colored\u001b[0m\n",
      "\u001b[32mBuilding wheel for colored (setup.py): started\u001b[0m\n",
      "\u001b[32mBuilding wheel for colored (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[32mCreated wheel for colored: filename=colored-1.4.3-py3-none-any.whl size=14323 sha256=965d659bce4fd3fc1a74148bda0393957084e8813169c65b4c6bf5ac0fe0b7fb\u001b[0m\n",
      "\u001b[32mStored in directory: /root/.cache/pip/wheels/b3/cf/a4/23200f342c1291c99b34a54e4997a6cd9ed23f58a924ddaa49\u001b[0m\n",
      "\u001b[32mSuccessfully built colored\u001b[0m\n",
      "\u001b[34mBuilding wheel for colored (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for colored: filename=colored-1.4.3-py3-none-any.whl size=14323 sha256=a6df423d3f73eae493647b0ef2ea480f4fcc02f91526157d4f3604f70e71d7ec\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/b3/cf/a4/23200f342c1291c99b34a54e4997a6cd9ed23f58a924ddaa49\u001b[0m\n",
      "\u001b[34mSuccessfully built colored\u001b[0m\n",
      "\u001b[35mBuilding wheel for colored (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mCreated wheel for colored: filename=colored-1.4.3-py3-none-any.whl size=14323 sha256=965d659bce4fd3fc1a74148bda0393957084e8813169c65b4c6bf5ac0fe0b7fb\u001b[0m\n",
      "\u001b[35mStored in directory: /root/.cache/pip/wheels/b3/cf/a4/23200f342c1291c99b34a54e4997a6cd9ed23f58a924ddaa49\u001b[0m\n",
      "\u001b[35mSuccessfully built colored\u001b[0m\n",
      "\u001b[32mInstalling collected packages: tokenizers, tensorboard-plugin-wit, colored, tensorboard-data-server, regex, pyDeprecate, pyasn1-modules, oauthlib, multidict, grpcio, frozenlist, filelock, cachetools, async-timeout, absl-py, yarl, torchmetrics, requests-oauthlib, markdown, huggingface-hub, google-auth, aiosignal, transformers, google-auth-oauthlib, aiohttp, watermark, tensorboard, pytorch-lightning\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tokenizers, tensorboard-plugin-wit, colored, tensorboard-data-server, regex, pyDeprecate, pyasn1-modules, oauthlib, multidict, grpcio, frozenlist, filelock, cachetools, async-timeout, absl-py, yarl, torchmetrics, requests-oauthlib, markdown, huggingface-hub, google-auth, aiosignal, transformers, google-auth-oauthlib, aiohttp, watermark, tensorboard, pytorch-lightning\u001b[0m\n",
      "\u001b[35mInstalling collected packages: tokenizers, tensorboard-plugin-wit, colored, tensorboard-data-server, regex, pyDeprecate, pyasn1-modules, oauthlib, multidict, grpcio, frozenlist, filelock, cachetools, async-timeout, absl-py, yarl, torchmetrics, requests-oauthlib, markdown, huggingface-hub, google-auth, aiosignal, transformers, google-auth-oauthlib, aiohttp, watermark, tensorboard, pytorch-lightning\u001b[0m\n",
      "\u001b[34mSuccessfully installed absl-py-1.1.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 cachetools-5.2.0 colored-1.4.3 filelock-3.7.1 frozenlist-1.3.0 google-auth-2.9.1 google-auth-oauthlib-0.4.6 grpcio-1.47.0 huggingface-hub-0.8.1 markdown-3.4.1 multidict-6.0.2 oauthlib-3.2.0 pyDeprecate-0.3.2 pyasn1-modules-0.2.8 pytorch-lightning-1.6.5 regex-2022.7.9 requests-oauthlib-1.3.1 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tokenizers-0.12.1 torchmetrics-0.9.2 transformers-4.20.1 watermark-2.3.1 yarl-1.7.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2022-07-18 19:21:45,542 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2022-07-18 19:21:45,542 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2022-07-18 19:21:45,602 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-3\",\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.16xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 32,\n",
      "        \"epochs\": 4,\n",
      "        \"learning-rate\": 2e-05\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.16xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-3\",\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"pytorch-training-2022-07-18-19-16-20-052\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-113969896847/pytorch-training-2022-07-18-19-16-20-052/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"multibert\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.16xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.16xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-3\",\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"multibert.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":32,\"epochs\":4,\"learning-rate\":2e-05}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=multibert.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"instance_groups\":[{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.16xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g4dn.16xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-3\",\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.16xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=multibert\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=64\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-113969896847/pytorch-training-2022-07-18-19-16-20-052/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.g4dn.16xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"hyperparameters\":{\"batch-size\":32,\"epochs\":4,\"learning-rate\":2e-05},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.16xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-training-2022-07-18-19-16-20-052\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-113969896847/pytorch-training-2022-07-18-19-16-20-052/source/sourcedir.tar.gz\",\"module_name\":\"multibert\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"instance_groups\":[{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.16xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"multibert.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"32\",\"--epochs\",\"4\",\"--learning-rate\",\"2e-05\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=4\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING-RATE=2e-05\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220716-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 multibert.py --batch-size 32 --epochs 4 --learning-rate 2e-05\u001b[0m\n",
      "\u001b[35mSuccessfully installed absl-py-1.1.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 cachetools-5.2.0 colored-1.4.3 filelock-3.7.1 frozenlist-1.3.0 google-auth-2.9.1 google-auth-oauthlib-0.4.6 grpcio-1.47.0 huggingface-hub-0.8.1 markdown-3.4.1 multidict-6.0.2 oauthlib-3.2.0 pyDeprecate-0.3.2 pyasn1-modules-0.2.8 pytorch-lightning-1.6.5 regex-2022.7.9 requests-oauthlib-1.3.1 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tokenizers-0.12.1 torchmetrics-0.9.2 transformers-4.20.1 watermark-2.3.1 yarl-1.7.2\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35m2022-07-18 19:21:45,752 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[35m2022-07-18 19:21:45,752 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[35m2022-07-18 19:21:45,815 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[35mTraining Env:\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-3\",\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.16xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 32,\n",
      "        \"epochs\": 4,\n",
      "        \"learning-rate\": 2e-05\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.16xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-3\",\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": false,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"pytorch-training-2022-07-18-19-16-20-052\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-113969896847/pytorch-training-2022-07-18-19-16-20-052/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"multibert\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"current_instance_type\": \"ml.g4dn.16xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.16xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-3\",\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"multibert.py\"\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mEnvironment variables:\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"batch-size\":32,\"epochs\":4,\"learning-rate\":2e-05}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=multibert.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.g4dn.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"instance_groups\":[{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.16xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_CURRENT_INSTANCE_TYPE=ml.g4dn.16xlarge\u001b[0m\n",
      "\u001b[35mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[35mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-3\",\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[35mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.16xlarge\"}}\u001b[0m\n",
      "\u001b[35mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[35mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=multibert\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=64\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-us-west-2-113969896847/pytorch-training-2022-07-18-19-16-20-052/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-2\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.g4dn.16xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"hyperparameters\":{\"batch-size\":32,\"epochs\":4,\"learning-rate\":2e-05},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.16xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-training-2022-07-18-19-16-20-052\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-113969896847/pytorch-training-2022-07-18-19-16-20-052/source/sourcedir.tar.gz\",\"module_name\":\"multibert\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.g4dn.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"instance_groups\":[{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.16xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"multibert.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--batch-size\",\"32\",\"--epochs\",\"4\",\"--learning-rate\",\"2e-05\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[35mSM_HP_BATCH-SIZE=32\u001b[0m\n",
      "\u001b[35mSM_HP_EPOCHS=4\u001b[0m\n",
      "\u001b[35mSM_HP_LEARNING-RATE=2e-05\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220716-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.8 multibert.py --batch-size 32 --epochs 4 --learning-rate 2e-05\u001b[0m\n",
      "\u001b[32mSuccessfully installed absl-py-1.1.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 cachetools-5.2.0 colored-1.4.3 filelock-3.7.1 frozenlist-1.3.0 google-auth-2.9.1 google-auth-oauthlib-0.4.6 grpcio-1.47.0 huggingface-hub-0.8.1 markdown-3.4.1 multidict-6.0.2 oauthlib-3.2.0 pyDeprecate-0.3.2 pyasn1-modules-0.2.8 pytorch-lightning-1.6.5 regex-2022.7.9 requests-oauthlib-1.3.1 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tokenizers-0.12.1 torchmetrics-0.9.2 transformers-4.20.1 watermark-2.3.1 yarl-1.7.2\u001b[0m\n",
      "\u001b[32mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[32m2022-07-18 19:21:46,014 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[32m2022-07-18 19:21:46,015 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[32m2022-07-18 19:21:46,077 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[32mTraining Env:\u001b[0m\n",
      "\u001b[32m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-3\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-3\",\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.16xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 32,\n",
      "        \"epochs\": 4,\n",
      "        \"learning-rate\": 2e-05\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.16xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-3\",\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": false,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"pytorch-training-2022-07-18-19-16-20-052\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-113969896847/pytorch-training-2022-07-18-19-16-20-052/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"multibert\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-3\",\n",
      "        \"current_instance_type\": \"ml.g4dn.16xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.16xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-3\",\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"multibert.py\"\u001b[0m\n",
      "\u001b[32m}\u001b[0m\n",
      "\u001b[32mEnvironment variables:\u001b[0m\n",
      "\u001b[32mSM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\"]\u001b[0m\n",
      "\u001b[32mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[32mSM_HPS={\"batch-size\":32,\"epochs\":4,\"learning-rate\":2e-05}\u001b[0m\n",
      "\u001b[32mSM_USER_ENTRY_POINT=multibert.py\u001b[0m\n",
      "\u001b[32mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[32mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-3\",\"current_instance_type\":\"ml.g4dn.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"instance_groups\":[{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.16xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[32mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[32mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[32mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[32mSM_CURRENT_HOST=algo-3\u001b[0m\n",
      "\u001b[32mSM_CURRENT_INSTANCE_TYPE=ml.g4dn.16xlarge\u001b[0m\n",
      "\u001b[32mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[32mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-3\",\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[32mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[32mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.16xlarge\"}}\u001b[0m\n",
      "\u001b[32mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[32mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[32mSM_MODULE_NAME=multibert\u001b[0m\n",
      "\u001b[32mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[32mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[32mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[32mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[32mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[32mSM_NUM_CPUS=64\u001b[0m\n",
      "\u001b[32mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[32mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[32mSM_MODULE_DIR=s3://sagemaker-us-west-2-113969896847/pytorch-training-2022-07-18-19-16-20-052/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[32mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-3\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.g4dn.16xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"hyperparameters\":{\"batch-size\":32,\"epochs\":4,\"learning-rate\":2e-05},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.16xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-training-2022-07-18-19-16-20-052\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-113969896847/pytorch-training-2022-07-18-19-16-20-052/source/sourcedir.tar.gz\",\"module_name\":\"multibert\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-3\",\"current_instance_type\":\"ml.g4dn.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\"],\"instance_groups\":[{\"hosts\":[\"algo-3\",\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.16xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"multibert.py\"}\u001b[0m\n",
      "\u001b[32mSM_USER_ARGS=[\"--batch-size\",\"32\",\"--epochs\",\"4\",\"--learning-rate\",\"2e-05\"]\u001b[0m\n",
      "\u001b[32mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[32mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[32mSM_HP_BATCH-SIZE=32\u001b[0m\n",
      "\u001b[32mSM_HP_EPOCHS=4\u001b[0m\n",
      "\u001b[32mSM_HP_LEARNING-RATE=2e-05\u001b[0m\n",
      "\u001b[32mPYTHONPATH=/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220716-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[32mInvoking script with the following command:\u001b[0m\n",
      "\u001b[32m/opt/conda/bin/python3.8 multibert.py --batch-size 32 --epochs 4 --learning-rate 2e-05\u001b[0m\n",
      "\u001b[34mclean_data_input: dataframe:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[34m0                                  Zuko gets bitches  ...            0.0\u001b[0m\n",
      "\u001b[34m1  Zimmerman we comin for yo life bitch. http://t...  ...            0.0\u001b[0m\n",
      "\u001b[34m2  Zhou Mi was just layin on his bed and SM just ...  ...            0.0\u001b[0m\n",
      "\u001b[34m3  Zelda bitches lol @joeylattime https://t.co/Cp...  ...            0.0\u001b[0m\n",
      "\u001b[34m4         Zack still questions my love for Oreos lol  ...            0.0\u001b[0m\n",
      "\u001b[34m5    Zach Huggins tell yo bitch to leave me tf alone  ...            0.0\u001b[0m\n",
      "\u001b[34m6  Yuu Hinouchi gets fucked by two guys until she...  ...            0.0\u001b[0m\n",
      "\u001b[34m7  Yup! RT @STheMisfit Then she got AIDs and died...  ...            0.0\u001b[0m\n",
      "\u001b[34m8  Yup, I officially do not like you. You are a n...  ...            0.0\u001b[0m\n",
      "\u001b[34m9              Yup RT @Durags4Eva: Egg nog trash rap  ...            0.0\u001b[0m\n",
      "\u001b[34m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[34mclean_data_input: column: tweet\u001b[0m\n",
      "\u001b[32mclean_data_input: dataframe:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[32m0                                  Zuko gets bitches  ...            0.0\u001b[0m\n",
      "\u001b[32m1  Zimmerman we comin for yo life bitch. http://t...  ...            0.0\u001b[0m\n",
      "\u001b[32m2  Zhou Mi was just layin on his bed and SM just ...  ...            0.0\u001b[0m\n",
      "\u001b[32m3  Zelda bitches lol @joeylattime https://t.co/Cp...  ...            0.0\u001b[0m\n",
      "\u001b[32m4         Zack still questions my love for Oreos lol  ...            0.0\u001b[0m\n",
      "\u001b[32m5    Zach Huggins tell yo bitch to leave me tf alone  ...            0.0\u001b[0m\n",
      "\u001b[32m6  Yuu Hinouchi gets fucked by two guys until she...  ...            0.0\u001b[0m\n",
      "\u001b[32m7  Yup! RT @STheMisfit Then she got AIDs and died...  ...            0.0\u001b[0m\n",
      "\u001b[32m8  Yup, I officially do not like you. You are a n...  ...            0.0\u001b[0m\n",
      "\u001b[32m9              Yup RT @Durags4Eva: Egg nog trash rap  ...            0.0\u001b[0m\n",
      "\u001b[32m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[32mclean_data_input: column: tweet\u001b[0m\n",
      "\u001b[32m/opt/ml/code/preprocessing.py:38: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dataframe[column] = dataframe[column].str.replace('[^A-Za-z0-9 ]+','')\u001b[0m\n",
      "\u001b[34m/opt/ml/code/preprocessing.py:38: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dataframe[column] = dataframe[column].str.replace('[^A-Za-z0-9 ]+','')\u001b[0m\n",
      "\u001b[34mclean_data_output: return_val:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[34m0                                  Zuko gets bitches  ...            0.0\u001b[0m\n",
      "\u001b[34m1             Zimmerman we comin for yo life bitch    ...            0.0\u001b[0m\n",
      "\u001b[34m2  Zhou Mi was just layin on his bed and SM just ...  ...            0.0\u001b[0m\n",
      "\u001b[34m3                               Zelda bitches lol     ...            0.0\u001b[0m\n",
      "\u001b[34m4         Zack still questions my love for Oreos lol  ...            0.0\u001b[0m\n",
      "\u001b[34m5    Zach Huggins tell yo bitch to leave me tf alone  ...            0.0\u001b[0m\n",
      "\u001b[34m6  Yuu Hinouchi gets fucked by two guys until she...  ...            0.0\u001b[0m\n",
      "\u001b[34m7  Yup   Then she got AIDs and died   Jenny was a...  ...            0.0\u001b[0m\n",
      "\u001b[34m8  Yup I officially do not like you You are a nee...  ...            0.0\u001b[0m\n",
      "\u001b[34m9                            Yup   Egg nog trash rap  ...            0.0\u001b[0m\n",
      "\u001b[34m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[34mclean_data completed!\u001b[0m\n",
      "\u001b[34m====================================================================================================\u001b[0m\n",
      "\u001b[34mto_int_input: dataframe:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[34m0                                  Zuko gets bitches  ...            0.0\u001b[0m\n",
      "\u001b[34m1             Zimmerman we comin for yo life bitch    ...            0.0\u001b[0m\n",
      "\u001b[34m2  Zhou Mi was just layin on his bed and SM just ...  ...            0.0\u001b[0m\n",
      "\u001b[34m3                               Zelda bitches lol     ...            0.0\u001b[0m\n",
      "\u001b[34m4         Zack still questions my love for Oreos lol  ...            0.0\u001b[0m\n",
      "\u001b[34m5    Zach Huggins tell yo bitch to leave me tf alone  ...            0.0\u001b[0m\n",
      "\u001b[34m6  Yuu Hinouchi gets fucked by two guys until she...  ...            0.0\u001b[0m\n",
      "\u001b[34m7  Yup   Then she got AIDs and died   Jenny was a...  ...            0.0\u001b[0m\n",
      "\u001b[34m8  Yup I officially do not like you You are a nee...  ...            0.0\u001b[0m\n",
      "\u001b[34m9                            Yup   Egg nog trash rap  ...            0.0\u001b[0m\n",
      "\u001b[34m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[34m/opt/ml/code/preprocessing.py:76: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[34mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[34mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'general criticsm']=dataframe.loc[:,'general criticsm'].astype(int)\u001b[0m\n",
      "\u001b[34m/opt/ml/code/preprocessing.py:77: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[34mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[34mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'disability shaming']=dataframe.loc[:,'disability shaming'].astype(int)\u001b[0m\n",
      "\u001b[34m/opt/ml/code/preprocessing.py:78: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[34mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[34mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'racial prejudice']=dataframe.loc[:,'racial prejudice'].astype(int)\u001b[0m\n",
      "\u001b[34m/opt/ml/code/preprocessing.py:79: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[34mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[34mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'sexism']=dataframe.loc[:,'sexism'].astype(int)\u001b[0m\n",
      "\u001b[34m/opt/ml/code/preprocessing.py:80: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[34mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[34mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'lgbtq+ phobia']=dataframe.loc[:,'lgbtq+ phobia'].astype(int)\u001b[0m\n",
      "\u001b[34mto_int_output: dataframe:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[34m0                                  Zuko gets bitches  ...              0\u001b[0m\n",
      "\u001b[34m1             Zimmerman we comin for yo life bitch    ...              0\u001b[0m\n",
      "\u001b[34m2  Zhou Mi was just layin on his bed and SM just ...  ...              0\u001b[0m\n",
      "\u001b[34m3                               Zelda bitches lol     ...              0\u001b[0m\n",
      "\u001b[34m4         Zack still questions my love for Oreos lol  ...              0\u001b[0m\n",
      "\u001b[34m5    Zach Huggins tell yo bitch to leave me tf alone  ...              0\u001b[0m\n",
      "\u001b[34m6  Yuu Hinouchi gets fucked by two guys until she...  ...              0\u001b[0m\n",
      "\u001b[34m7  Yup   Then she got AIDs and died   Jenny was a...  ...              0\u001b[0m\n",
      "\u001b[34m8  Yup I officially do not like you You are a nee...  ...              0\u001b[0m\n",
      "\u001b[34m9                            Yup   Egg nog trash rap  ...              0\u001b[0m\n",
      "\u001b[34m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[34mto_int completed!\u001b[0m\n",
      "\u001b[34m==================================================\u001b[0m\n",
      "\u001b[34msplit_data_input: dataframe:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[34m0                                  Zuko gets bitches  ...            0.0\u001b[0m\n",
      "\u001b[34m1             Zimmerman we comin for yo life bitch    ...            0.0\u001b[0m\n",
      "\u001b[34m2  Zhou Mi was just layin on his bed and SM just ...  ...            0.0\u001b[0m\n",
      "\u001b[34m3                               Zelda bitches lol     ...            0.0\u001b[0m\n",
      "\u001b[34m4         Zack still questions my love for Oreos lol  ...            0.0\u001b[0m\n",
      "\u001b[34m5    Zach Huggins tell yo bitch to leave me tf alone  ...            0.0\u001b[0m\n",
      "\u001b[34m6  Yuu Hinouchi gets fucked by two guys until she...  ...            0.0\u001b[0m\n",
      "\u001b[34m7  Yup   Then she got AIDs and died   Jenny was a...  ...            0.0\u001b[0m\n",
      "\u001b[34m8  Yup I officially do not like you You are a nee...  ...            0.0\u001b[0m\n",
      "\u001b[34m9                            Yup   Egg nog trash rap  ...            0.0\u001b[0m\n",
      "\u001b[34m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[34msplit_data_output: train_df:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[34m17091                          bitch u kno my game tight  ...            0.0\u001b[0m\n",
      "\u001b[34m9455             all these damn bitches on my phone line  ...            0.0\u001b[0m\n",
      "\u001b[34m6221       Who got time to be  Thats aint wassup no more  ...            0.0\u001b[0m\n",
      "\u001b[34m22054   gross ill stick with my galaxy it will still ...  ...            0.0\u001b[0m\n",
      "\u001b[34m24141   just dont bitch when your power goes out like...  ...            0.0\u001b[0m\n",
      "\u001b[34m8683          Parque de atracciones abandonado en Japn    ...            0.0\u001b[0m\n",
      "\u001b[34m5184     using words such as dick and pussy in regula...  ...            0.0\u001b[0m\n",
      "\u001b[34m2364   They come to you out of the blue They make oth...  ...            0.0\u001b[0m\n",
      "\u001b[34m18841   Up making plays can I have my slut bitch girl...  ...            0.0\u001b[0m\n",
      "\u001b[34m10028  real nigga shit she wanna be a righteous young...  ...            0.0\u001b[0m\n",
      "\u001b[34m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[34msplit_data_output: val_df:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[34m14425  I dont like when niggahs be like Na Ill check ...  ...            0.0\u001b[0m\n",
      "\u001b[34m24629   Hey at least shes got a nice smile amp a grea...  ...            0.0\u001b[0m\n",
      "\u001b[34m21323                                  aint that a bitch  ...            0.0\u001b[0m\n",
      "\u001b[34m17041  Bitches be watching me from other bitches page...  ...            0.0\u001b[0m\n",
      "\u001b[34m2643   The spot is open for you take so your better g...  ...            0.0\u001b[0m\n",
      "\u001b[34m9443              Tell your bitch that Im that nigga now  ...            0.0\u001b[0m\n",
      "\u001b[34m16117  dont try to be nice to me after you were being...  ...            0.0\u001b[0m\n",
      "\u001b[34m16596  Chase the pussy its a sin Falls in ya lap its ...  ...            0.0\u001b[0m\n",
      "\u001b[34m19818                tounge punching smelly turtle pussy  ...            0.0\u001b[0m\n",
      "\u001b[34m1035         Who told this midget hoe to start stripping  ...            0.0\u001b[0m\n",
      "\u001b[34m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[34msplit_data completed!\u001b[0m\n",
      "\u001b[34m====================================================================================================\u001b[0m\n",
      "\u001b[34mlabel_cols_input: dataframe:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[34m17091                          bitch u kno my game tight  ...            0.0\u001b[0m\n",
      "\u001b[34m9455             all these damn bitches on my phone line  ...            0.0\u001b[0m\n",
      "\u001b[34m6221       Who got time to be  Thats aint wassup no more  ...            0.0\u001b[0m\n",
      "\u001b[34m22054   gross ill stick with my galaxy it will still ...  ...            0.0\u001b[0m\n",
      "\u001b[34m24141   just dont bitch when your power goes out like...  ...            0.0\u001b[0m\n",
      "\u001b[34m8683          Parque de atracciones abandonado en Japn    ...            0.0\u001b[0m\n",
      "\u001b[34m5184     using words such as dick and pussy in regula...  ...            0.0\u001b[0m\n",
      "\u001b[34m2364   They come to you out of the blue They make oth...  ...            0.0\u001b[0m\n",
      "\u001b[34m18841   Up making plays can I have my slut bitch girl...  ...            0.0\u001b[0m\n",
      "\u001b[34m10028  real nigga shit she wanna be a righteous young...  ...            0.0\u001b[0m\n",
      "\u001b[34m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[34mlabel_cols_output: ['disability shaming', 'racial prejudice', 'sexism', 'lgbtq+ phobia']\u001b[0m\n",
      "\u001b[34mlabel_cols completed!\u001b[0m\n",
      "\u001b[34m====================================================================================================\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 29.0/29.0 [00:00<00:00, 33.2kB/s]\u001b[0m\n",
      "\u001b[35mclean_data_input: dataframe:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[35m0                                  Zuko gets bitches  ...            0.0\u001b[0m\n",
      "\u001b[35m1  Zimmerman we comin for yo life bitch. http://t...  ...            0.0\u001b[0m\n",
      "\u001b[35m2  Zhou Mi was just layin on his bed and SM just ...  ...            0.0\u001b[0m\n",
      "\u001b[35m3  Zelda bitches lol @joeylattime https://t.co/Cp...  ...            0.0\u001b[0m\n",
      "\u001b[35m4         Zack still questions my love for Oreos lol  ...            0.0\u001b[0m\n",
      "\u001b[35m5    Zach Huggins tell yo bitch to leave me tf alone  ...            0.0\u001b[0m\n",
      "\u001b[35m6  Yuu Hinouchi gets fucked by two guys until she...  ...            0.0\u001b[0m\n",
      "\u001b[35m7  Yup! RT @STheMisfit Then she got AIDs and died...  ...            0.0\u001b[0m\n",
      "\u001b[35m8  Yup, I officially do not like you. You are a n...  ...            0.0\u001b[0m\n",
      "\u001b[35m9              Yup RT @Durags4Eva: Egg nog trash rap  ...            0.0\u001b[0m\n",
      "\u001b[35m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[35mclean_data_input: column: tweet\u001b[0m\n",
      "\u001b[35m/opt/ml/code/preprocessing.py:38: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dataframe[column] = dataframe[column].str.replace('[^A-Za-z0-9 ]+','')\u001b[0m\n",
      "\u001b[35mclean_data_output: return_val:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[35m0                                  Zuko gets bitches  ...            0.0\u001b[0m\n",
      "\u001b[35m1             Zimmerman we comin for yo life bitch    ...            0.0\u001b[0m\n",
      "\u001b[35m2  Zhou Mi was just layin on his bed and SM just ...  ...            0.0\u001b[0m\n",
      "\u001b[35m3                               Zelda bitches lol     ...            0.0\u001b[0m\n",
      "\u001b[35m4         Zack still questions my love for Oreos lol  ...            0.0\u001b[0m\n",
      "\u001b[35m5    Zach Huggins tell yo bitch to leave me tf alone  ...            0.0\u001b[0m\n",
      "\u001b[35m6  Yuu Hinouchi gets fucked by two guys until she...  ...            0.0\u001b[0m\n",
      "\u001b[35m7  Yup   Then she got AIDs and died   Jenny was a...  ...            0.0\u001b[0m\n",
      "\u001b[35m8  Yup I officially do not like you You are a nee...  ...            0.0\u001b[0m\n",
      "\u001b[35m9                            Yup   Egg nog trash rap  ...            0.0\u001b[0m\n",
      "\u001b[35m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[35mclean_data completed!\u001b[0m\n",
      "\u001b[35m====================================================================================================\u001b[0m\n",
      "\u001b[35mto_int_input: dataframe:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[35m0                                  Zuko gets bitches  ...            0.0\u001b[0m\n",
      "\u001b[35m1             Zimmerman we comin for yo life bitch    ...            0.0\u001b[0m\n",
      "\u001b[35m2  Zhou Mi was just layin on his bed and SM just ...  ...            0.0\u001b[0m\n",
      "\u001b[35m3                               Zelda bitches lol     ...            0.0\u001b[0m\n",
      "\u001b[35m4         Zack still questions my love for Oreos lol  ...            0.0\u001b[0m\n",
      "\u001b[35m5    Zach Huggins tell yo bitch to leave me tf alone  ...            0.0\u001b[0m\n",
      "\u001b[35m6  Yuu Hinouchi gets fucked by two guys until she...  ...            0.0\u001b[0m\n",
      "\u001b[35m7  Yup   Then she got AIDs and died   Jenny was a...  ...            0.0\u001b[0m\n",
      "\u001b[35m8  Yup I officially do not like you You are a nee...  ...            0.0\u001b[0m\n",
      "\u001b[35m9                            Yup   Egg nog trash rap  ...            0.0\u001b[0m\n",
      "\u001b[35m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[35m/opt/ml/code/preprocessing.py:76: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[35mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[35mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[35mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'general criticsm']=dataframe.loc[:,'general criticsm'].astype(int)\u001b[0m\n",
      "\u001b[35m/opt/ml/code/preprocessing.py:77: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[35mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[35mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[35mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'disability shaming']=dataframe.loc[:,'disability shaming'].astype(int)\u001b[0m\n",
      "\u001b[35m/opt/ml/code/preprocessing.py:78: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[35mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[35mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[35mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'racial prejudice']=dataframe.loc[:,'racial prejudice'].astype(int)\u001b[0m\n",
      "\u001b[35m/opt/ml/code/preprocessing.py:79: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[35mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[35mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[35mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'sexism']=dataframe.loc[:,'sexism'].astype(int)\u001b[0m\n",
      "\u001b[35m/opt/ml/code/preprocessing.py:80: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[35mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[35mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[35mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'lgbtq+ phobia']=dataframe.loc[:,'lgbtq+ phobia'].astype(int)\u001b[0m\n",
      "\u001b[35mto_int_output: dataframe:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[35m0                                  Zuko gets bitches  ...              0\u001b[0m\n",
      "\u001b[35m1             Zimmerman we comin for yo life bitch    ...              0\u001b[0m\n",
      "\u001b[35m2  Zhou Mi was just layin on his bed and SM just ...  ...              0\u001b[0m\n",
      "\u001b[35m3                               Zelda bitches lol     ...              0\u001b[0m\n",
      "\u001b[35m4         Zack still questions my love for Oreos lol  ...              0\u001b[0m\n",
      "\u001b[35m5    Zach Huggins tell yo bitch to leave me tf alone  ...              0\u001b[0m\n",
      "\u001b[35m6  Yuu Hinouchi gets fucked by two guys until she...  ...              0\u001b[0m\n",
      "\u001b[35m7  Yup   Then she got AIDs and died   Jenny was a...  ...              0\u001b[0m\n",
      "\u001b[35m8  Yup I officially do not like you You are a nee...  ...              0\u001b[0m\n",
      "\u001b[35m9                            Yup   Egg nog trash rap  ...              0\u001b[0m\n",
      "\u001b[35m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[35mto_int completed!\u001b[0m\n",
      "\u001b[35m==================================================\u001b[0m\n",
      "\u001b[35msplit_data_input: dataframe:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[35m0                                  Zuko gets bitches  ...            0.0\u001b[0m\n",
      "\u001b[35m1             Zimmerman we comin for yo life bitch    ...            0.0\u001b[0m\n",
      "\u001b[35m2  Zhou Mi was just layin on his bed and SM just ...  ...            0.0\u001b[0m\n",
      "\u001b[35m3                               Zelda bitches lol     ...            0.0\u001b[0m\n",
      "\u001b[35m4         Zack still questions my love for Oreos lol  ...            0.0\u001b[0m\n",
      "\u001b[35m5    Zach Huggins tell yo bitch to leave me tf alone  ...            0.0\u001b[0m\n",
      "\u001b[35m6  Yuu Hinouchi gets fucked by two guys until she...  ...            0.0\u001b[0m\n",
      "\u001b[35m7  Yup   Then she got AIDs and died   Jenny was a...  ...            0.0\u001b[0m\n",
      "\u001b[35m8  Yup I officially do not like you You are a nee...  ...            0.0\u001b[0m\n",
      "\u001b[35m9                            Yup   Egg nog trash rap  ...            0.0\u001b[0m\n",
      "\u001b[35m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[35msplit_data_output: train_df:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[35m20672   word Do any of ur decisions include anchor fe...  ...            0.0\u001b[0m\n",
      "\u001b[35m20000                   I love you hoe Hahahhaa  UglyAss  ...            0.0\u001b[0m\n",
      "\u001b[35m7525     I hate seeing a nice fee wit a weak nigga  B...  ...            0.0\u001b[0m\n",
      "\u001b[35m8540     Was just handed this on my flight Must be in...  ...            0.0\u001b[0m\n",
      "\u001b[35m18244  ExplainAnAnimePlotBadly Boy with a monkey tail...  ...            0.0\u001b[0m\n",
      "\u001b[35m15740                      Fly as a bitch on Aladdin rug  ...            0.0\u001b[0m\n",
      "\u001b[35m22636   really u use in another nigga name and u foll...  ...            1.0\u001b[0m\n",
      "\u001b[35m15937                Every bitch was born to break a man  ...            0.0\u001b[0m\n",
      "\u001b[35m1768   Tyga and Drake two light skin bitches but if h...  ...            0.0\u001b[0m\n",
      "\u001b[35m5205     Whats with all these pussies turning themsel...  ...            0.0\u001b[0m\n",
      "\u001b[35m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[35msplit_data_output: val_df:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[35m5847               big booty bitches  big booty bitches   ...            0.0\u001b[0m\n",
      "\u001b[35m12987  If I ever saw Kendall Jones in person Id kill ...  ...            0.0\u001b[0m\n",
      "\u001b[35m1456                                  We in this bitch    ...            0.0\u001b[0m\n",
      "\u001b[35m22532   shoulda came to my familys dinner tonightwe t...  ...            0.0\u001b[0m\n",
      "\u001b[35m5164                  Leave the bitching to the bitches   ...            0.0\u001b[0m\n",
      "\u001b[35m6773                        I dive in tha pussy like      ...            0.0\u001b[0m\n",
      "\u001b[35m16284                           Dem hoe accessories dea   ...            0.0\u001b[0m\n",
      "\u001b[35m13759  I rather watch the oak cliff redskins and oak ...  ...            0.0\u001b[0m\n",
      "\u001b[35m5954                                         kill whitey  ...            0.0\u001b[0m\n",
      "\u001b[35m7469        you aint a bad bitch if you got bad habits    ...            0.0\u001b[0m\n",
      "\u001b[35m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[35msplit_data completed!\u001b[0m\n",
      "\u001b[35m====================================================================================================\u001b[0m\n",
      "\u001b[35mlabel_cols_input: dataframe:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[35m20672   word Do any of ur decisions include anchor fe...  ...            0.0\u001b[0m\n",
      "\u001b[35m20000                   I love you hoe Hahahhaa  UglyAss  ...            0.0\u001b[0m\n",
      "\u001b[35m7525     I hate seeing a nice fee wit a weak nigga  B...  ...            0.0\u001b[0m\n",
      "\u001b[35m8540     Was just handed this on my flight Must be in...  ...            0.0\u001b[0m\n",
      "\u001b[35m18244  ExplainAnAnimePlotBadly Boy with a monkey tail...  ...            0.0\u001b[0m\n",
      "\u001b[35m15740                      Fly as a bitch on Aladdin rug  ...            0.0\u001b[0m\n",
      "\u001b[35m22636   really u use in another nigga name and u foll...  ...            1.0\u001b[0m\n",
      "\u001b[35m15937                Every bitch was born to break a man  ...            0.0\u001b[0m\n",
      "\u001b[35m1768   Tyga and Drake two light skin bitches but if h...  ...            0.0\u001b[0m\n",
      "\u001b[35m5205     Whats with all these pussies turning themsel...  ...            0.0\u001b[0m\n",
      "\u001b[35m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[35mlabel_cols_output: ['disability shaming', 'racial prejudice', 'sexism', 'lgbtq+ phobia']\u001b[0m\n",
      "\u001b[35mlabel_cols completed!\u001b[0m\n",
      "\u001b[35m====================================================================================================\u001b[0m\n",
      "\u001b[35mDownloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35mDownloading: 100%|██████████| 29.0/29.0 [00:00<00:00, 42.8kB/s]\u001b[0m\n",
      "\u001b[32mclean_data_output: return_val:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[32m0                                  Zuko gets bitches  ...            0.0\u001b[0m\n",
      "\u001b[32m1             Zimmerman we comin for yo life bitch    ...            0.0\u001b[0m\n",
      "\u001b[32m2  Zhou Mi was just layin on his bed and SM just ...  ...            0.0\u001b[0m\n",
      "\u001b[32m3                               Zelda bitches lol     ...            0.0\u001b[0m\n",
      "\u001b[32m4         Zack still questions my love for Oreos lol  ...            0.0\u001b[0m\n",
      "\u001b[32m5    Zach Huggins tell yo bitch to leave me tf alone  ...            0.0\u001b[0m\n",
      "\u001b[32m6  Yuu Hinouchi gets fucked by two guys until she...  ...            0.0\u001b[0m\n",
      "\u001b[32m7  Yup   Then she got AIDs and died   Jenny was a...  ...            0.0\u001b[0m\n",
      "\u001b[32m8  Yup I officially do not like you You are a nee...  ...            0.0\u001b[0m\n",
      "\u001b[32m9                            Yup   Egg nog trash rap  ...            0.0\u001b[0m\n",
      "\u001b[32m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[32mclean_data completed!\u001b[0m\n",
      "\u001b[32m====================================================================================================\u001b[0m\n",
      "\u001b[32mto_int_input: dataframe:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[32m0                                  Zuko gets bitches  ...            0.0\u001b[0m\n",
      "\u001b[32m1             Zimmerman we comin for yo life bitch    ...            0.0\u001b[0m\n",
      "\u001b[32m2  Zhou Mi was just layin on his bed and SM just ...  ...            0.0\u001b[0m\n",
      "\u001b[32m3                               Zelda bitches lol     ...            0.0\u001b[0m\n",
      "\u001b[32m4         Zack still questions my love for Oreos lol  ...            0.0\u001b[0m\n",
      "\u001b[32m5    Zach Huggins tell yo bitch to leave me tf alone  ...            0.0\u001b[0m\n",
      "\u001b[32m6  Yuu Hinouchi gets fucked by two guys until she...  ...            0.0\u001b[0m\n",
      "\u001b[32m7  Yup   Then she got AIDs and died   Jenny was a...  ...            0.0\u001b[0m\n",
      "\u001b[32m8  Yup I officially do not like you You are a nee...  ...            0.0\u001b[0m\n",
      "\u001b[32m9                            Yup   Egg nog trash rap  ...            0.0\u001b[0m\n",
      "\u001b[32m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[32m/opt/ml/code/preprocessing.py:76: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[32mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[32mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[32mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'general criticsm']=dataframe.loc[:,'general criticsm'].astype(int)\u001b[0m\n",
      "\u001b[32m/opt/ml/code/preprocessing.py:77: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[32mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[32mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[32mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'disability shaming']=dataframe.loc[:,'disability shaming'].astype(int)\u001b[0m\n",
      "\u001b[32m/opt/ml/code/preprocessing.py:78: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[32mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[32mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[32mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'racial prejudice']=dataframe.loc[:,'racial prejudice'].astype(int)\u001b[0m\n",
      "\u001b[32m/opt/ml/code/preprocessing.py:79: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[32mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[32mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[32mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'sexism']=dataframe.loc[:,'sexism'].astype(int)\u001b[0m\n",
      "\u001b[32m/opt/ml/code/preprocessing.py:80: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[32mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[32mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
      "\u001b[32mSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.loc[:,'lgbtq+ phobia']=dataframe.loc[:,'lgbtq+ phobia'].astype(int)\u001b[0m\n",
      "\u001b[32mto_int_output: dataframe:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[32m0                                  Zuko gets bitches  ...              0\u001b[0m\n",
      "\u001b[32m1             Zimmerman we comin for yo life bitch    ...              0\u001b[0m\n",
      "\u001b[32m2  Zhou Mi was just layin on his bed and SM just ...  ...              0\u001b[0m\n",
      "\u001b[32m3                               Zelda bitches lol     ...              0\u001b[0m\n",
      "\u001b[32m4         Zack still questions my love for Oreos lol  ...              0\u001b[0m\n",
      "\u001b[32m5    Zach Huggins tell yo bitch to leave me tf alone  ...              0\u001b[0m\n",
      "\u001b[32m6  Yuu Hinouchi gets fucked by two guys until she...  ...              0\u001b[0m\n",
      "\u001b[32m7  Yup   Then she got AIDs and died   Jenny was a...  ...              0\u001b[0m\n",
      "\u001b[32m8  Yup I officially do not like you You are a nee...  ...              0\u001b[0m\n",
      "\u001b[32m9                            Yup   Egg nog trash rap  ...              0\u001b[0m\n",
      "\u001b[32m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[32mto_int completed!\u001b[0m\n",
      "\u001b[32m==================================================\u001b[0m\n",
      "\u001b[32msplit_data_input: dataframe:                                                tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[32m0                                  Zuko gets bitches  ...            0.0\u001b[0m\n",
      "\u001b[32m1             Zimmerman we comin for yo life bitch    ...            0.0\u001b[0m\n",
      "\u001b[32m2  Zhou Mi was just layin on his bed and SM just ...  ...            0.0\u001b[0m\n",
      "\u001b[32m3                               Zelda bitches lol     ...            0.0\u001b[0m\n",
      "\u001b[32m4         Zack still questions my love for Oreos lol  ...            0.0\u001b[0m\n",
      "\u001b[32m5    Zach Huggins tell yo bitch to leave me tf alone  ...            0.0\u001b[0m\n",
      "\u001b[32m6  Yuu Hinouchi gets fucked by two guys until she...  ...            0.0\u001b[0m\n",
      "\u001b[32m7  Yup   Then she got AIDs and died   Jenny was a...  ...            0.0\u001b[0m\n",
      "\u001b[32m8  Yup I officially do not like you You are a nee...  ...            0.0\u001b[0m\n",
      "\u001b[32m9                            Yup   Egg nog trash rap  ...            0.0\u001b[0m\n",
      "\u001b[32m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[32msplit_data_output: train_df:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[32m17882   A dude with money can only impress a broke bitch  ...            0.0\u001b[0m\n",
      "\u001b[32m18125  pornandroidiphoneipadsexxxx  Latina  Latina wi...  ...            0.0\u001b[0m\n",
      "\u001b[32m21989   Then send them bitches through express mail o...  ...            0.0\u001b[0m\n",
      "\u001b[32m7023        lmfaooo girlfights ghetto ratchet  bitch ...  ...            0.0\u001b[0m\n",
      "\u001b[32m12221  Just seen a dude wearing all black and white o...  ...            0.0\u001b[0m\n",
      "\u001b[32m17224  Because Id rather wear my hair long and have p...  ...            1.0\u001b[0m\n",
      "\u001b[32m7026      Kayci and I greet each other by saying like...  ...            0.0\u001b[0m\n",
      "\u001b[32m14282                      I got bad bitches on stand by  ...            0.0\u001b[0m\n",
      "\u001b[32m4249     Why yall hoes in such a hurry to be single m...  ...            0.0\u001b[0m\n",
      "\u001b[32m16481  countin all my hoes nigga thats all i knows nigga  ...            0.0\u001b[0m\n",
      "\u001b[32m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[32msplit_data_output: val_df:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[32m3695          She gonna pop that pussy for a real niggaa  ...            0.0\u001b[0m\n",
      "\u001b[32m7173     I wonder if the hoes are gonna give Hallowee...  ...            0.0\u001b[0m\n",
      "\u001b[32m13324  Im about to push this niggah off my seat tryin...  ...            0.0\u001b[0m\n",
      "\u001b[32m22037   nigga what bitch Im talking bout boxing can u...  ...            0.0\u001b[0m\n",
      "\u001b[32m12556  ISIS Jihadis In Australia Shoot Man In The Fac...  ...            0.0\u001b[0m\n",
      "\u001b[32m23722                       just FaceTime Doms bitch ass  ...            0.0\u001b[0m\n",
      "\u001b[32m18086          Shoutout to everybody that follow a nicca  ...            0.0\u001b[0m\n",
      "\u001b[32m7219     Media Matters executive behind StopRush camp...  ...            1.0\u001b[0m\n",
      "\u001b[32m13420  i wont get catfished anymore tho bc im no long...  ...            0.0\u001b[0m\n",
      "\u001b[32m2656   The Rick ScottCharlie Crist ads have been runn...  ...            0.0\u001b[0m\n",
      "\u001b[32m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[32msplit_data completed!\u001b[0m\n",
      "\u001b[32m====================================================================================================\u001b[0m\n",
      "\u001b[32mlabel_cols_input: dataframe:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[32m17882   A dude with money can only impress a broke bitch  ...            0.0\u001b[0m\n",
      "\u001b[32m18125  pornandroidiphoneipadsexxxx  Latina  Latina wi...  ...            0.0\u001b[0m\n",
      "\u001b[32m21989   Then send them bitches through express mail o...  ...            0.0\u001b[0m\n",
      "\u001b[32m7023        lmfaooo girlfights ghetto ratchet  bitch ...  ...            0.0\u001b[0m\n",
      "\u001b[32m12221  Just seen a dude wearing all black and white o...  ...            0.0\u001b[0m\n",
      "\u001b[32m17224  Because Id rather wear my hair long and have p...  ...            1.0\u001b[0m\n",
      "\u001b[32m7026      Kayci and I greet each other by saying like...  ...            0.0\u001b[0m\n",
      "\u001b[32m14282                      I got bad bitches on stand by  ...            0.0\u001b[0m\n",
      "\u001b[32m4249     Why yall hoes in such a hurry to be single m...  ...            0.0\u001b[0m\n",
      "\u001b[32m16481  countin all my hoes nigga thats all i knows nigga  ...            0.0\u001b[0m\n",
      "\u001b[32m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[32mlabel_cols_output: ['disability shaming', 'racial prejudice', 'sexism', 'lgbtq+ phobia']\u001b[0m\n",
      "\u001b[32mlabel_cols completed!\u001b[0m\n",
      "\u001b[32m====================================================================================================\u001b[0m\n",
      "\u001b[32mDownloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[32mDownloading: 100%|██████████| 29.0/29.0 [00:00<00:00, 21.7kB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/208k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading:  40%|███▉      | 83.0k/208k [00:00<00:00, 648kB/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 208k/208k [00:00<00:00, 1.21MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:   0%|          | 0.00/208k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35mDownloading:  17%|█▋        | 36.0k/208k [00:00<00:00, 274kB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  94%|█████████▍| 196k/208k [00:00<00:00, 933kB/s]\u001b[0m\n",
      "\u001b[35mDownloading: 100%|██████████| 208k/208k [00:00<00:00, 871kB/s]\u001b[0m\n",
      "\u001b[32mDownloading:   0%|          | 0.00/208k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[32mDownloading:  18%|█▊        | 38.0k/208k [00:00<00:00, 282kB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  96%|█████████▋| 201k/208k [00:00<00:00, 924kB/s]\u001b[0m\n",
      "\u001b[32mDownloading: 100%|██████████| 208k/208k [00:00<00:00, 844kB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/426k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading:   8%|▊         | 36.0k/426k [00:00<00:01, 312kB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  44%|████▍     | 188k/426k [00:00<00:00, 978kB/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 426k/426k [00:00<00:00, 1.47MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:   0%|          | 0.00/426k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35mDownloading:  19%|█▉        | 80.0k/426k [00:00<00:00, 716kB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  48%|████▊     | 203k/426k [00:00<00:00, 1.02MB/s]\u001b[0m\n",
      "\u001b[35mDownloading: 100%|██████████| 426k/426k [00:00<00:00, 2.00MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:   0%|          | 0.00/426k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[32mDownloading:   7%|▋         | 28.0k/426k [00:00<00:01, 225kB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  44%|████▍     | 188k/426k [00:00<00:00, 944kB/s]\u001b[0m\n",
      "\u001b[32mDownloading: 100%|██████████| 426k/426k [00:00<00:00, 1.36MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/570 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 570/570 [00:00<00:00, 763kB/s]\u001b[0m\n",
      "\u001b[34mcreate_tokenizer_output: tokenizer: PreTrainedTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\u001b[0m\n",
      "\u001b[34mcreate_tokenizer completed!\u001b[0m\n",
      "\u001b[34m====================================================================================================\u001b[0m\n",
      "\u001b[34mcreate_data_module_input: train_df:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[34m17091                          bitch u kno my game tight  ...            0.0\u001b[0m\n",
      "\u001b[34m9455             all these damn bitches on my phone line  ...            0.0\u001b[0m\n",
      "\u001b[34m6221       Who got time to be  Thats aint wassup no more  ...            0.0\u001b[0m\n",
      "\u001b[34m22054   gross ill stick with my galaxy it will still ...  ...            0.0\u001b[0m\n",
      "\u001b[34m24141   just dont bitch when your power goes out like...  ...            0.0\u001b[0m\n",
      "\u001b[34m8683          Parque de atracciones abandonado en Japn    ...            0.0\u001b[0m\n",
      "\u001b[34m5184     using words such as dick and pussy in regula...  ...            0.0\u001b[0m\n",
      "\u001b[34m2364   They come to you out of the blue They make oth...  ...            0.0\u001b[0m\n",
      "\u001b[34m18841   Up making plays can I have my slut bitch girl...  ...            0.0\u001b[0m\n",
      "\u001b[34m10028  real nigga shit she wanna be a righteous young...  ...            0.0\u001b[0m\n",
      "\u001b[34m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[34mcreate_data_module_input: val_df:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[34m14425  I dont like when niggahs be like Na Ill check ...  ...            0.0\u001b[0m\n",
      "\u001b[34m24629   Hey at least shes got a nice smile amp a grea...  ...            0.0\u001b[0m\n",
      "\u001b[34m21323                                  aint that a bitch  ...            0.0\u001b[0m\n",
      "\u001b[34m17041  Bitches be watching me from other bitches page...  ...            0.0\u001b[0m\n",
      "\u001b[34m2643   The spot is open for you take so your better g...  ...            0.0\u001b[0m\n",
      "\u001b[34m9443              Tell your bitch that Im that nigga now  ...            0.0\u001b[0m\n",
      "\u001b[34m16117  dont try to be nice to me after you were being...  ...            0.0\u001b[0m\n",
      "\u001b[34m16596  Chase the pussy its a sin Falls in ya lap its ...  ...            0.0\u001b[0m\n",
      "\u001b[34m19818                tounge punching smelly turtle pussy  ...            0.0\u001b[0m\n",
      "\u001b[34m1035         Who told this midget hoe to start stripping  ...            0.0\u001b[0m\n",
      "\u001b[34m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[34mcreate_data_module_output: data_module: <create_model.TweetsDataModule object at 0x7f2cfb34c9a0>\u001b[0m\n",
      "\u001b[34mcreate_data_module completed!\u001b[0m\n",
      "\u001b[34m====================================================================================================\u001b[0m\n",
      "\u001b[34mwarmup_and_totaltraining_steps completed!\u001b[0m\n",
      "\u001b[34m====================================================================================================\u001b[0m\n",
      "\u001b[34mtrain_model_input: LABEL_COLUMNS: ['disability shaming', 'racial prejudice', 'sexism', 'lgbtq+ phobia']\u001b[0m\n",
      "\u001b[34mtrain_model_input: warmup_steps: 522\u001b[0m\n",
      "\u001b[34mtrain_model_input: total_training_steps: 2612\u001b[0m\n",
      "\u001b[34mtrain_model_input: data_module: <create_model.TweetsDataModule object at 0x7f2cfb34c9a0>\u001b[0m\n",
      "\u001b[32mDownloading:   0%|          | 0.00/570 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[32mDownloading: 100%|██████████| 570/570 [00:00<00:00, 599kB/s]\u001b[0m\n",
      "\u001b[32mcreate_tokenizer_output: tokenizer: PreTrainedTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\u001b[0m\n",
      "\u001b[32mcreate_tokenizer completed!\u001b[0m\n",
      "\u001b[32m====================================================================================================\u001b[0m\n",
      "\u001b[32mcreate_data_module_input: train_df:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[32m17882   A dude with money can only impress a broke bitch  ...            0.0\u001b[0m\n",
      "\u001b[32m18125  pornandroidiphoneipadsexxxx  Latina  Latina wi...  ...            0.0\u001b[0m\n",
      "\u001b[32m21989   Then send them bitches through express mail o...  ...            0.0\u001b[0m\n",
      "\u001b[32m7023        lmfaooo girlfights ghetto ratchet  bitch ...  ...            0.0\u001b[0m\n",
      "\u001b[32m12221  Just seen a dude wearing all black and white o...  ...            0.0\u001b[0m\n",
      "\u001b[32m17224  Because Id rather wear my hair long and have p...  ...            1.0\u001b[0m\n",
      "\u001b[32m7026      Kayci and I greet each other by saying like...  ...            0.0\u001b[0m\n",
      "\u001b[32m14282                      I got bad bitches on stand by  ...            0.0\u001b[0m\n",
      "\u001b[32m4249     Why yall hoes in such a hurry to be single m...  ...            0.0\u001b[0m\n",
      "\u001b[32m16481  countin all my hoes nigga thats all i knows nigga  ...            0.0\u001b[0m\n",
      "\u001b[32m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[32mcreate_data_module_input: val_df:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[32m3695          She gonna pop that pussy for a real niggaa  ...            0.0\u001b[0m\n",
      "\u001b[32m7173     I wonder if the hoes are gonna give Hallowee...  ...            0.0\u001b[0m\n",
      "\u001b[32m13324  Im about to push this niggah off my seat tryin...  ...            0.0\u001b[0m\n",
      "\u001b[32m22037   nigga what bitch Im talking bout boxing can u...  ...            0.0\u001b[0m\n",
      "\u001b[32m12556  ISIS Jihadis In Australia Shoot Man In The Fac...  ...            0.0\u001b[0m\n",
      "\u001b[32m23722                       just FaceTime Doms bitch ass  ...            0.0\u001b[0m\n",
      "\u001b[32m18086          Shoutout to everybody that follow a nicca  ...            0.0\u001b[0m\n",
      "\u001b[32m7219     Media Matters executive behind StopRush camp...  ...            1.0\u001b[0m\n",
      "\u001b[32m13420  i wont get catfished anymore tho bc im no long...  ...            0.0\u001b[0m\n",
      "\u001b[32m2656   The Rick ScottCharlie Crist ads have been runn...  ...            0.0\u001b[0m\n",
      "\u001b[32m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[32mcreate_data_module_output: data_module: <create_model.TweetsDataModule object at 0x7efdc6eb3f70>\u001b[0m\n",
      "\u001b[32mcreate_data_module completed!\u001b[0m\n",
      "\u001b[32m====================================================================================================\u001b[0m\n",
      "\u001b[32mwarmup_and_totaltraining_steps completed!\u001b[0m\n",
      "\u001b[32m====================================================================================================\u001b[0m\n",
      "\u001b[32mtrain_model_input: LABEL_COLUMNS: ['disability shaming', 'racial prejudice', 'sexism', 'lgbtq+ phobia']\u001b[0m\n",
      "\u001b[32mtrain_model_input: warmup_steps: 522\u001b[0m\n",
      "\u001b[32mtrain_model_input: total_training_steps: 2612\u001b[0m\n",
      "\u001b[32mtrain_model_input: data_module: <create_model.TweetsDataModule object at 0x7efdc6eb3f70>\u001b[0m\n",
      "\u001b[35mDownloading:   0%|          | 0.00/570 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35mDownloading: 100%|██████████| 570/570 [00:00<00:00, 844kB/s]\u001b[0m\n",
      "\u001b[35mcreate_tokenizer_output: tokenizer: PreTrainedTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\u001b[0m\n",
      "\u001b[35mcreate_tokenizer completed!\u001b[0m\n",
      "\u001b[35m====================================================================================================\u001b[0m\n",
      "\u001b[35mcreate_data_module_input: train_df:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[35m20672   word Do any of ur decisions include anchor fe...  ...            0.0\u001b[0m\n",
      "\u001b[35m20000                   I love you hoe Hahahhaa  UglyAss  ...            0.0\u001b[0m\n",
      "\u001b[35m7525     I hate seeing a nice fee wit a weak nigga  B...  ...            0.0\u001b[0m\n",
      "\u001b[35m8540     Was just handed this on my flight Must be in...  ...            0.0\u001b[0m\n",
      "\u001b[35m18244  ExplainAnAnimePlotBadly Boy with a monkey tail...  ...            0.0\u001b[0m\n",
      "\u001b[35m15740                      Fly as a bitch on Aladdin rug  ...            0.0\u001b[0m\n",
      "\u001b[35m22636   really u use in another nigga name and u foll...  ...            1.0\u001b[0m\n",
      "\u001b[35m15937                Every bitch was born to break a man  ...            0.0\u001b[0m\n",
      "\u001b[35m1768   Tyga and Drake two light skin bitches but if h...  ...            0.0\u001b[0m\n",
      "\u001b[35m5205     Whats with all these pussies turning themsel...  ...            0.0\u001b[0m\n",
      "\u001b[35m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[35mcreate_data_module_input: val_df:                                                    tweet  ...  lgbtq+ phobia\u001b[0m\n",
      "\u001b[35m5847               big booty bitches  big booty bitches   ...            0.0\u001b[0m\n",
      "\u001b[35m12987  If I ever saw Kendall Jones in person Id kill ...  ...            0.0\u001b[0m\n",
      "\u001b[35m1456                                  We in this bitch    ...            0.0\u001b[0m\n",
      "\u001b[35m22532   shoulda came to my familys dinner tonightwe t...  ...            0.0\u001b[0m\n",
      "\u001b[35m5164                  Leave the bitching to the bitches   ...            0.0\u001b[0m\n",
      "\u001b[35m6773                        I dive in tha pussy like      ...            0.0\u001b[0m\n",
      "\u001b[35m16284                           Dem hoe accessories dea   ...            0.0\u001b[0m\n",
      "\u001b[35m13759  I rather watch the oak cliff redskins and oak ...  ...            0.0\u001b[0m\n",
      "\u001b[35m5954                                         kill whitey  ...            0.0\u001b[0m\n",
      "\u001b[35m7469        you aint a bad bitch if you got bad habits    ...            0.0\u001b[0m\n",
      "\u001b[35m[10 rows x 6 columns]\u001b[0m\n",
      "\u001b[35mcreate_data_module_output: data_module: <create_model.TweetsDataModule object at 0x7f8371d52790>\u001b[0m\n",
      "\u001b[35mcreate_data_module completed!\u001b[0m\n",
      "\u001b[35m====================================================================================================\u001b[0m\n",
      "\u001b[35mwarmup_and_totaltraining_steps completed!\u001b[0m\n",
      "\u001b[35m====================================================================================================\u001b[0m\n",
      "\u001b[35mtrain_model_input: LABEL_COLUMNS: ['disability shaming', 'racial prejudice', 'sexism', 'lgbtq+ phobia']\u001b[0m\n",
      "\u001b[35mtrain_model_input: warmup_steps: 522\u001b[0m\n",
      "\u001b[35mtrain_model_input: total_training_steps: 2612\u001b[0m\n",
      "\u001b[35mtrain_model_input: data_module: <create_model.TweetsDataModule object at 0x7f8371d52790>\u001b[0m\n",
      "\u001b[35mDownloading:   0%|          | 0.00/416M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading:   0%|          | 0.00/416M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading:   2%|▏         | 7.55M/416M [00:00<00:05, 79.2MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:   0%|          | 0.00/416M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[32mDownloading:   2%|▏         | 7.67M/416M [00:00<00:05, 80.4MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:   4%|▍         | 17.4M/416M [00:00<00:04, 93.3MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:   7%|▋         | 27.3M/416M [00:00<00:04, 97.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   4%|▍         | 17.4M/416M [00:00<00:04, 93.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   7%|▋         | 27.3M/416M [00:00<00:04, 98.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:   9%|▉         | 37.3M/416M [00:00<00:03, 101MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  11%|█▏        | 47.3M/416M [00:00<00:03, 102MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  14%|█▍        | 57.2M/416M [00:00<00:03, 103MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  16%|█▌        | 67.0M/416M [00:00<00:03, 103MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  19%|█▊        | 77.0M/416M [00:00<00:03, 103MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  21%|██        | 86.8M/416M [00:00<00:03, 103MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  23%|██▎       | 96.8M/416M [00:01<00:03, 104MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  26%|██▌       | 107M/416M [00:01<00:03, 104MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:   2%|▏         | 7.62M/416M [00:00<00:05, 79.9MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:   4%|▍         | 17.5M/416M [00:00<00:04, 93.9MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:   7%|▋         | 27.5M/416M [00:00<00:04, 98.7MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:   9%|▉         | 37.5M/416M [00:00<00:03, 101MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  11%|█▏        | 47.4M/416M [00:00<00:03, 102MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  14%|█▍        | 57.4M/416M [00:00<00:03, 103MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  16%|█▌        | 67.4M/416M [00:00<00:03, 104MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  19%|█▊        | 77.4M/416M [00:00<00:03, 104MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  21%|██        | 87.3M/416M [00:00<00:03, 104MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  23%|██▎       | 97.3M/416M [00:01<00:03, 104MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:   9%|▉         | 37.1M/416M [00:00<00:03, 100MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  11%|█▏        | 47.0M/416M [00:00<00:03, 101MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  14%|█▎        | 56.8M/416M [00:00<00:03, 102MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  16%|█▌        | 66.7M/416M [00:00<00:03, 102MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  18%|█▊        | 76.5M/416M [00:00<00:03, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  21%|██        | 86.4M/416M [00:00<00:03, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  23%|██▎       | 96.2M/416M [00:01<00:03, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  26%|██▌       | 106M/416M [00:01<00:03, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  28%|██▊       | 116M/416M [00:01<00:03, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  30%|███       | 126M/416M [00:01<00:02, 103MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  28%|██▊       | 117M/416M [00:01<00:03, 104MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  30%|███       | 127M/416M [00:01<00:02, 104MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  33%|███▎      | 137M/416M [00:01<00:02, 104MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  35%|███▌      | 146M/416M [00:01<00:02, 104MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  38%|███▊      | 156M/416M [00:01<00:02, 104MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  40%|████      | 166M/416M [00:01<00:02, 104MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  42%|████▏     | 176M/416M [00:01<00:02, 105MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  45%|████▍     | 186M/416M [00:01<00:02, 105MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  47%|████▋     | 196M/416M [00:02<00:02, 105MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  50%|████▉     | 206M/416M [00:02<00:02, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  26%|██▌       | 107M/416M [00:01<00:03, 104MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  28%|██▊       | 117M/416M [00:01<00:02, 104MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  31%|███       | 127M/416M [00:01<00:02, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  33%|███▎      | 137M/416M [00:01<00:02, 104MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  35%|███▌      | 147M/416M [00:01<00:02, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  38%|███▊      | 157M/416M [00:01<00:02, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  40%|████      | 167M/416M [00:01<00:02, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  43%|████▎     | 177M/416M [00:01<00:02, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  45%|████▌     | 187M/416M [00:01<00:02, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  47%|████▋     | 197M/416M [00:02<00:02, 105MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  33%|███▎      | 136M/416M [00:01<00:02, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  35%|███▌      | 146M/416M [00:01<00:02, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  37%|███▋      | 155M/416M [00:01<00:02, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  40%|███▉      | 165M/416M [00:01<00:02, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  42%|████▏     | 175M/416M [00:01<00:02, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  44%|████▍     | 185M/416M [00:01<00:02, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  47%|████▋     | 195M/416M [00:02<00:02, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  49%|████▉     | 205M/416M [00:02<00:02, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  52%|█████▏    | 214M/416M [00:02<00:02, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  54%|█████▍    | 224M/416M [00:02<00:01, 103MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  52%|█████▏    | 216M/416M [00:02<00:01, 105MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  54%|█████▍    | 226M/416M [00:02<00:01, 105MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  57%|█████▋    | 236M/416M [00:02<00:01, 105MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  59%|█████▉    | 246M/416M [00:02<00:01, 105MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  62%|██████▏   | 256M/416M [00:02<00:01, 104MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  64%|██████▍   | 266M/416M [00:02<00:01, 104MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  66%|██████▋   | 276M/416M [00:02<00:01, 104MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  69%|██████▉   | 286M/416M [00:02<00:01, 104MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  71%|███████▏  | 296M/416M [00:03<00:01, 104MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  74%|███████▎  | 306M/416M [00:03<00:01, 104MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  50%|████▉     | 207M/416M [00:02<00:02, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  52%|█████▏    | 217M/416M [00:02<00:01, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  55%|█████▍    | 227M/416M [00:02<00:01, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  57%|█████▋    | 237M/416M [00:02<00:01, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  59%|█████▉    | 247M/416M [00:02<00:01, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  62%|██████▏   | 257M/416M [00:02<00:01, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  64%|██████▍   | 267M/416M [00:02<00:01, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  67%|██████▋   | 277M/416M [00:02<00:01, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  69%|██████▉   | 287M/416M [00:02<00:01, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  72%|███████▏  | 297M/416M [00:03<00:01, 105MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  56%|█████▋    | 234M/416M [00:02<00:01, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  59%|█████▊    | 244M/416M [00:02<00:01, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  61%|██████    | 254M/416M [00:02<00:01, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  63%|██████▎   | 264M/416M [00:02<00:01, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  66%|██████▌   | 273M/416M [00:02<00:01, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  68%|██████▊   | 283M/416M [00:02<00:01, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  71%|███████   | 293M/416M [00:03<00:01, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  73%|███████▎  | 303M/416M [00:03<00:01, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  75%|███████▌  | 313M/416M [00:03<00:01, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  78%|███████▊  | 323M/416M [00:03<00:00, 103MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  76%|███████▌  | 316M/416M [00:03<00:00, 104MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  79%|███████▊  | 326M/416M [00:03<00:00, 105MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  81%|████████  | 336M/416M [00:03<00:00, 105MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  83%|████████▎ | 346M/416M [00:03<00:00, 105MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  86%|████████▌ | 356M/416M [00:03<00:00, 105MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  88%|████████▊ | 366M/416M [00:03<00:00, 105MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  91%|█████████ | 376M/416M [00:03<00:00, 104MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  93%|█████████▎| 386M/416M [00:03<00:00, 104MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  95%|█████████▌| 396M/416M [00:04<00:00, 104MB/s]\u001b[0m\n",
      "\u001b[34mDownloading:  98%|█████████▊| 406M/416M [00:04<00:00, 104MB/s]\u001b[0m\n",
      "\u001b[34mDownloading: 100%|██████████| 416M/416M [00:04<00:00, 104MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  74%|███████▍  | 307M/416M [00:03<00:01, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  76%|███████▋  | 317M/416M [00:03<00:00, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  79%|███████▊  | 327M/416M [00:03<00:00, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  81%|████████  | 337M/416M [00:03<00:00, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  84%|████████▎ | 347M/416M [00:03<00:00, 105MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  86%|████████▌ | 357M/416M [00:03<00:00, 104MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  88%|████████▊ | 367M/416M [00:03<00:00, 104MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  91%|█████████ | 377M/416M [00:03<00:00, 104MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  93%|█████████▎| 387M/416M [00:03<00:00, 104MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  96%|█████████▌| 397M/416M [00:04<00:00, 104MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  80%|████████  | 332M/416M [00:03<00:00, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  82%|████████▏ | 342M/416M [00:03<00:00, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  85%|████████▍ | 352M/416M [00:03<00:00, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  87%|████████▋ | 362M/416M [00:03<00:00, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  89%|████████▉ | 372M/416M [00:03<00:00, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  92%|█████████▏| 382M/416M [00:03<00:00, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  94%|█████████▍| 392M/416M [00:04<00:00, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  97%|█████████▋| 401M/416M [00:04<00:00, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading:  99%|█████████▉| 411M/416M [00:04<00:00, 103MB/s]\u001b[0m\n",
      "\u001b[32mDownloading: 100%|██████████| 416M/416M [00:04<00:00, 103MB/s]\u001b[0m\n",
      "\u001b[35mDownloading:  98%|█████████▊| 407M/416M [00:04<00:00, 104MB/s]\u001b[0m\n",
      "\u001b[35mDownloading: 100%|██████████| 416M/416M [00:04<00:00, 104MB/s]\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:151: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f302ffdef40>)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f302ffdef40>)`.\n",
      "  rank_zero_deprecation(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=30)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\u001b[0m\n",
      "\u001b[34mGPU available: True, used: True\u001b[0m\n",
      "\u001b[34mTPU available: False, using: 0 TPU cores\u001b[0m\n",
      "\u001b[34mIPU available: False, using: 0 IPUs\u001b[0m\n",
      "\u001b[34mHPU available: False, using: 0 HPUs\u001b[0m\n",
      "\u001b[34mMissing logger folder: /opt/ml/code/lightning_logs\u001b[0m\n",
      "\u001b[35mSome weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\u001b[0m\n",
      "\u001b[35m- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[35m- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[32mSome weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\u001b[0m\n",
      "\u001b[32m- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[32m- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:151: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f0106f28f40>)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f0106f28f40>)`.\n",
      "  rank_zero_deprecation(\u001b[0m\n",
      "\u001b[32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=30)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\u001b[0m\n",
      "\u001b[32mGPU available: True, used: True\u001b[0m\n",
      "\u001b[32mTPU available: False, using: 0 TPU cores\u001b[0m\n",
      "\u001b[32mIPU available: False, using: 0 IPUs\u001b[0m\n",
      "\u001b[32mHPU available: False, using: 0 HPUs\u001b[0m\n",
      "\u001b[32mMissing logger folder: /opt/ml/code/lightning_logs\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:151: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f8334f56f40>)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f8334f56f40>)`.\n",
      "  rank_zero_deprecation(\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=30)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\u001b[0m\n",
      "\u001b[35mGPU available: True, used: True\u001b[0m\n",
      "\u001b[35mTPU available: False, using: 0 TPU cores\u001b[0m\n",
      "\u001b[35mIPU available: False, using: 0 IPUs\u001b[0m\n",
      "\u001b[35mHPU available: False, using: 0 HPUs\u001b[0m\n",
      "\u001b[35mMissing logger folder: /opt/ml/code/lightning_logs\u001b[0m\n",
      "\u001b[35mLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[35m| Name       | Type      | Params\u001b[0m\n",
      "\u001b[35m-----------------------------------------\u001b[0m\n",
      "\u001b[35m0 | bert       | BertModel | 108 M \u001b[0m\n",
      "\u001b[35m1 | classifier | Linear    | 3.1 K \u001b[0m\n",
      "\u001b[35m2 | criterion  | BCELoss   | 0     \u001b[0m\n",
      "\u001b[35m-----------------------------------------\u001b[0m\n",
      "\u001b[35m108 M     Trainable params\u001b[0m\n",
      "\u001b[35m0         Non-trainable params\u001b[0m\n",
      "\u001b[35m108 M     Total params\u001b[0m\n",
      "\u001b[35m433.253   Total estimated model params size (MB)\u001b[0m\n",
      "\u001b[35mSanity Checking: 0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.015 algo-2:57 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220716-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220716-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[32mLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[0m\n",
      "\u001b[32m/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[32m| Name       | Type      | Params\u001b[0m\n",
      "\u001b[32m-----------------------------------------\u001b[0m\n",
      "\u001b[32m0 | bert       | BertModel | 108 M \u001b[0m\n",
      "\u001b[32m1 | classifier | Linear    | 3.1 K \u001b[0m\n",
      "\u001b[32m2 | criterion  | BCELoss   | 0     \u001b[0m\n",
      "\u001b[32m-----------------------------------------\u001b[0m\n",
      "\u001b[32m108 M     Trainable params\u001b[0m\n",
      "\u001b[32m0         Non-trainable params\u001b[0m\n",
      "\u001b[32m108 M     Total params\u001b[0m\n",
      "\u001b[32m433.253   Total estimated model params size (MB)\u001b[0m\n",
      "\u001b[32mSanity Checking: 0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.087 algo-3:57 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[32m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220716-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[32m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220716-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.216 algo-3:57 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.218 algo-3:57 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.218 algo-3:57 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.218 algo-3:57 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.218 algo-3:57 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[32mSanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[32mSanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.541 algo-3:57 INFO hook.py:560] name:bert.embeddings.word_embeddings.weight count_params:22268928\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.541 algo-3:57 INFO hook.py:560] name:bert.embeddings.position_embeddings.weight count_params:393216\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.541 algo-3:57 INFO hook.py:560] name:bert.embeddings.token_type_embeddings.weight count_params:1536\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.541 algo-3:57 INFO hook.py:560] name:bert.embeddings.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.541 algo-3:57 INFO hook.py:560] name:bert.embeddings.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.541 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.541 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.541 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.541 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.541 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.0.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.0.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.0.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.0.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.0.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.0.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.1.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.1.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.1.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.1.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.1.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.1.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.2.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.542 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.2.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.2.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.2.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.2.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.2.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.3.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.3.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.3.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.3.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.3.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.3.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.4.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.4.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.4.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.4.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.4.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.543 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.4.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.5.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.5.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.5.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.5.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.5.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.5.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.6.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.6.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.6.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.6.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.6.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.6.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.544 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.7.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.7.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.7.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.7.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.7.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.7.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.8.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.8.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.8.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.8.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.8.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.8.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.9.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.9.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.9.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.9.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.9.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.9.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.545 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.10.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.10.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.10.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.10.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.10.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.10.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.11.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.11.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.11.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.11.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.11.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.encoder.layer.11.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.pooler.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:bert.pooler.dense.bias count_params:768\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:classifier.weight count_params:3072\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:560] name:classifier.bias count_params:4\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.546 algo-3:57 INFO hook.py:562] Total Trainable Params: 108313348\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.547 algo-3:57 INFO hook.py:421] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[32m[2022-07-18 19:22:11.547 algo-3:57 INFO hook.py:485] Hook is writing from the hook with pid: 57\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.146 algo-2:57 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.147 algo-2:57 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.148 algo-2:57 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.148 algo-2:57 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.148 algo-2:57 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[35mSanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[35mSanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.519 algo-2:57 INFO hook.py:560] name:bert.embeddings.word_embeddings.weight count_params:22268928\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.519 algo-2:57 INFO hook.py:560] name:bert.embeddings.position_embeddings.weight count_params:393216\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.519 algo-2:57 INFO hook.py:560] name:bert.embeddings.token_type_embeddings.weight count_params:1536\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.519 algo-2:57 INFO hook.py:560] name:bert.embeddings.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.519 algo-2:57 INFO hook.py:560] name:bert.embeddings.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.519 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.519 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.519 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.519 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.519 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.519 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.519 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.519 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.0.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.0.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.0.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.0.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.0.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.0.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.1.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.1.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.1.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.1.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.1.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.1.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.2.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.2.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.2.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.520 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.2.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.2.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.2.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.3.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.3.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.3.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.3.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.3.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.3.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.4.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.4.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.4.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.4.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.4.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.4.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.521 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.5.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.5.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.5.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.5.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.5.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.5.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.6.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.6.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.6.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.6.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.6.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.6.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.7.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.522 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.7.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.7.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.7.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.7.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.7.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.8.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.8.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.8.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.8.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.8.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.8.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.9.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.9.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.9.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.9.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.9.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.9.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.523 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.10.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.10.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.10.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.10.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.10.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.10.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.11.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.11.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.11.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.11.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.11.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.encoder.layer.11.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.pooler.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:bert.pooler.dense.bias count_params:768\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:classifier.weight count_params:3072\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:560] name:classifier.bias count_params:4\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:562] Total Trainable Params: 108313348\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.524 algo-2:57 INFO hook.py:421] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[35m[2022-07-18 19:22:11.525 algo-2:57 INFO hook.py:485] Hook is writing from the hook with pid: 57\u001b[0m\n",
      "\u001b[35mSanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 11.70it/s]\u001b[0m\n",
      "\u001b[35mSanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 11.70it/s]\u001b[0m\n",
      "\u001b[35mTraining: 0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[35mTraining:   0%|          | 0/727 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[35mEpoch 0:   0%|          | 0/727 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[32mSanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  9.31it/s]\u001b[0m\n",
      "\u001b[32mSanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  9.31it/s]\u001b[0m\n",
      "\u001b[32mTraining: 0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[32mTraining:   0%|          | 0/727 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[32mEpoch 0:   0%|          | 0/727 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m| Name       | Type      | Params\u001b[0m\n",
      "\u001b[34m-----------------------------------------\u001b[0m\n",
      "\u001b[34m0 | bert       | BertModel | 108 M \u001b[0m\n",
      "\u001b[34m1 | classifier | Linear    | 3.1 K \u001b[0m\n",
      "\u001b[34m2 | criterion  | BCELoss   | 0     \u001b[0m\n",
      "\u001b[34m-----------------------------------------\u001b[0m\n",
      "\u001b[34m108 M     Trainable params\u001b[0m\n",
      "\u001b[34m0         Non-trainable params\u001b[0m\n",
      "\u001b[34m108 M     Total params\u001b[0m\n",
      "\u001b[34m433.253   Total estimated model params size (MB)\u001b[0m\n",
      "\u001b[34mSanity Checking: 0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.294 algo-1:57 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220716-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220716-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.423 algo-1:57 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.424 algo-1:57 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.424 algo-1:57 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.425 algo-1:57 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.425 algo-1:57 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mSanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mSanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.embeddings.word_embeddings.weight count_params:22268928\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.embeddings.position_embeddings.weight count_params:393216\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.embeddings.token_type_embeddings.weight count_params:1536\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.embeddings.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.embeddings.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.0.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.0.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.0.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.0.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.0.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.0.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.0.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.811 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.1.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.1.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.1.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.1.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.1.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.1.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.1.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.2.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.2.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.2.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.2.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.2.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.2.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.2.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.812 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.3.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.3.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.3.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.3.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.3.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.3.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.3.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.4.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.4.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.4.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.4.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.4.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.4.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.4.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.5.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.5.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.5.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.5.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.5.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.5.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.5.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.813 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.6.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.6.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.6.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.6.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.6.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.6.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.6.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.7.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.7.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.7.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.7.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.7.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.7.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.7.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.814 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.8.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.8.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.8.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.8.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.8.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.8.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.8.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.9.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.9.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.9.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.9.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.9.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.9.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.9.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.10.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.10.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.10.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.10.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.10.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.10.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.815 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.10.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.self.query.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.self.query.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.self.key.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.self.key.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.self.value.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.self.value.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.11.attention.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.11.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.11.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.11.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.11.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.11.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:560] name:bert.encoder.layer.11.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:560] name:bert.pooler.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:560] name:bert.pooler.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:560] name:classifier.weight count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:560] name:classifier.bias count_params:4\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:562] Total Trainable Params: 108313348\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.816 algo-1:57 INFO hook.py:421] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-07-18 19:22:13.817 algo-1:57 INFO hook.py:485] Hook is writing from the hook with pid: 57\u001b[0m\n",
      "\u001b[34mSanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 11.40it/s]\u001b[0m\n",
      "\u001b[34mSanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 11.40it/s]\u001b[0m\n",
      "\u001b[34mTraining: 0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mTraining:   0%|          | 0/727 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mEpoch 0:   0%|          | 0/727 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[35mEpoch 0:   4%|▍         | 30/727 [00:08<03:23,  3.42it/s]\u001b[0m\n",
      "\u001b[35mEpoch 0:   4%|▍         | 30/727 [00:08<03:24,  3.42it/s]\u001b[0m\n",
      "\u001b[35mEpoch 0:   4%|▍         | 30/727 [00:08<03:24,  3.41it/s, loss=0.742, v_num=0, train_loss=0.735]\u001b[0m\n",
      "\u001b[32mEpoch 0:   4%|▍         | 30/727 [00:09<03:34,  3.25it/s]\u001b[0m\n",
      "\u001b[32mEpoch 0:   4%|▍         | 30/727 [00:09<03:34,  3.25it/s]\u001b[0m\n",
      "\u001b[32mEpoch 0:   4%|▍         | 30/727 [00:09<03:34,  3.24it/s, loss=0.725, v_num=0, train_loss=0.731]\u001b[0m\n",
      "\u001b[34mEpoch 0:   4%|▍         | 30/727 [00:08<03:24,  3.41it/s]#015Epoch 0:   4%|▍         | 30/727 [00:08<03:24,  3.41it/s]\u001b[0m\n",
      "\u001b[34mEpoch 0:   4%|▍         | 30/727 [00:08<03:24,  3.40it/s, loss=0.801, v_num=0, train_loss=0.785]\u001b[0m\n",
      "\u001b[35mEpoch 0:   8%|▊         | 60/727 [00:17<03:12,  3.47it/s, loss=0.742, v_num=0, train_loss=0.735]\u001b[0m\n",
      "\u001b[35mEpoch 0:   8%|▊         | 60/727 [00:17<03:12,  3.47it/s, loss=0.742, v_num=0, train_loss=0.735]\u001b[0m\n",
      "\u001b[35mEpoch 0:   8%|▊         | 60/727 [00:17<03:12,  3.47it/s, loss=0.677, v_num=0, train_loss=0.642]\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115\u001b[0m\n",
      "\u001b[35m: operator(): block: [0,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [100,0\u001b[0m\n",
      "\u001b[35m,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115\u001b[0m\n",
      "\u001b[35m: operator(): block: [0,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115\u001b[0m\n",
      "\u001b[35m: operator(): block: [0,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 723, in _call_and_handle_interrupt\u001b[0m\n",
      "\u001b[35mreturn trainer_fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\u001b[0m\n",
      "\u001b[35mresults = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\u001b[0m\n",
      "\u001b[35mresults = self._run_stage()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\u001b[0m\n",
      "\u001b[35mreturn self._run_train()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\u001b[0m\n",
      "\u001b[35mself.fit_loop.run()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 204, in run\u001b[0m\n",
      "\u001b[35mself.advance(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 266, in advance\u001b[0m\n",
      "\u001b[35mself._outputs = self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 204, in run\u001b[0m\n",
      "\u001b[35mself.advance(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 208, in advance\u001b[0m\n",
      "\u001b[35mbatch_output = self.batch_loop.run(batch, batch_idx)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 204, in run\u001b[0m\n",
      "\u001b[35mself.advance(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 88, in advance\u001b[0m\n",
      "\u001b[35moutputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 204, in run\u001b[0m\n",
      "\u001b[35mself.advance(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 203, in advance\u001b[0m\n",
      "\u001b[35mresult = self._run_optimization(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 256, in _run_optimization\u001b[0m\n",
      "\u001b[35mself._optimizer_step(optimizer, opt_idx, batch_idx, closure)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 369, in _optimizer_step\u001b[0m\n",
      "\u001b[35mself.trainer._call_lightning_module_hook(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1595, in _call_lightning_module_hook\u001b[0m\n",
      "\u001b[35moutput = fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py\", line 1646, in optimizer_step\u001b[0m\n",
      "\u001b[35moptimizer.step(closure=optimizer_closure)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py\", line 168, in step\u001b[0m\n",
      "\u001b[35mstep_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py\", line 193, in optimizer_step\u001b[0m\n",
      "\u001b[35mreturn self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 155, in optimizer_step\u001b[0m\n",
      "\u001b[35mreturn optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\u001b[0m\n",
      "\u001b[35mreturn wrapped(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\u001b[0m\n",
      "\u001b[35mreturn func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/optimization.py\", line 333, in step\u001b[0m\n",
      "\u001b[35mloss = closure()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 140, in _wrap_closure\u001b[0m\n",
      "\u001b[35mclosure_result = closure()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 148, in __call__\u001b[0m\n",
      "\u001b[35mself._result = self.closure(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 143, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 311, in backward_fn\u001b[0m\n",
      "\u001b[35mself.trainer._call_strategy_hook(\"backward\", loss, optimizer, opt_idx)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1765, in _call_strategy_hook\u001b[0m\n",
      "\u001b[35moutput = fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py\", line 168, in backward\u001b[0m\n",
      "\u001b[35mself.precision_plugin.backward(self.lightning_module, closure_loss, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 80, in backward\u001b[0m\n",
      "\u001b[35mmodel.backward(closure_loss, optimizer, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py\", line 1391, in backward\u001b[0m\n",
      "\u001b[35mloss.backward(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/_tensor.py\", line 363, in backward\u001b[0m\n",
      "\u001b[35mtorch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 173, in backward\u001b[0m\n",
      "\u001b[35mVariable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\u001b[0m\n",
      "\u001b[35mRuntimeError: CUDA error: device-side assert triggered\u001b[0m\n",
      "\u001b[35mCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\u001b[0m\n",
      "\u001b[35mFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\u001b[0m\n",
      "\u001b[35mFile \"multibert.py\", line 147, in <module>\u001b[0m\n",
      "\u001b[35mmultibert_classifier = model(train_df)\n",
      "  File \"multibert.py\", line 76, in model\n",
      "    train_model(LABEL_COLUMNS, warmup_steps, total_training_steps, data_module)\n",
      "  File \"/opt/ml/code/create_model.py\", line 308, in train_model\u001b[0m\n",
      "\u001b[35mtrainer.fit(model, data_module)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 770, in fit\u001b[0m\n",
      "\u001b[35mself._call_and_handle_interrupt(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 738, in _call_and_handle_interrupt\u001b[0m\n",
      "\u001b[35mself._teardown()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1300, in _teardown\u001b[0m\n",
      "\u001b[35mself.strategy.teardown()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py\", line 93, in teardown\u001b[0m\n",
      "\u001b[35msuper().teardown()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py\", line 444, in teardown\u001b[0m\n",
      "\u001b[35moptimizers_to_device(self.optimizers, torch.device(\"cpu\"))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/optimizer.py\", line 27, in optimizers_to_device\u001b[0m\n",
      "\u001b[35moptimizer_to_device(opt, device)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/optimizer.py\", line 33, in optimizer_to_device\u001b[0m\n",
      "\u001b[35moptimizer.state[p] = apply_to_collection(v, torch.Tensor, move_data_to_device, device)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 107, in apply_to_collection\u001b[0m\n",
      "\u001b[35mv = apply_to_collection(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 99, in apply_to_collection\u001b[0m\n",
      "\u001b[35mreturn function(data, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 354, in move_data_to_device\u001b[0m\n",
      "\u001b[35mreturn apply_to_collection(batch, dtype=dtype, function=batch_to)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 99, in apply_to_collection\u001b[0m\n",
      "\u001b[35mreturn function(data, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 347, in batch_to\u001b[0m\n",
      "\u001b[35mdata_output = data.to(device, **kwargs)\u001b[0m\n",
      "\u001b[35mRuntimeError\u001b[0m\n",
      "\u001b[35m: CUDA error: device-side assert triggered\u001b[0m\n",
      "\u001b[35mCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\u001b[0m\n",
      "\u001b[35mFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\u001b[0m\n",
      "\u001b[35m2022-07-18 19:22:31,734 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[35m2022-07-18 19:22:31,734 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\u001b[0m\n",
      "\u001b[35m2022-07-18 19:22:31,735 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[35m2022-07-18 19:22:31,735 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[35mExitCode 1\u001b[0m\n",
      "\u001b[35mErrorMessage \"RuntimeError: CUDA error: device-side assert triggered\n",
      " CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      " For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      " \n",
      " During handling of the above exception, another exception occurred\n",
      " Traceback (most recent call last)\n",
      " File \"multibert.py\", line 147, in <module>\n",
      " multibert_classifier = model(train_df)\n",
      " File \"multibert.py\", line 76, in model\n",
      " train_model(LABEL_COLUMNS, warmup_steps, total_training_steps, data_module)\n",
      " File \"/opt/ml/code/create_model.py\", line 308, in train_model\n",
      " trainer.fit(model, data_module)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 770, in fit\n",
      " self._call_and_handle_interrupt(\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 738, in _call_and_handle_interrupt\n",
      " self._teardown()\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1300, in _teardown\n",
      " self.strategy.teardown()\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py\", line 93, in teardown\n",
      " super().teardown()\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py\", line 444, in teardown\n",
      " optimizers_to_device(self.optimizers, torch.device(\"cpu\"))\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/optimizer.py\", line 27, in optimizers_to_device\n",
      " optimizer_to_device(opt, device)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/optimizer.py\", line 33, in optimizer_to_device\n",
      " optimizer.state[p] = apply_to_collection(v, torch.Tensor, move_data_to_device, device)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 107, in apply_to_collection\n",
      " v = apply_to_collection(\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 99, in apply_to_collection\n",
      " return function(data, *args, **kwargs)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 354, in move_data_to_device\n",
      " return apply_to_collection(batch, dtype=dtype, function=batch_to)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 347, in batch_to\n",
      " data_output = data.to(device, **kwargs)\n",
      " RuntimeError\n",
      " CUDA error: device-side assert triggered\"\u001b[0m\n",
      "\u001b[35mCommand \"/opt/conda/bin/python3.8 multibert.py --batch-size 32 --epochs 4 --learning-rate 2e-05\"\u001b[0m\n",
      "\u001b[35m2022-07-18 19:22:31,735 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\n",
      "2022-07-18 19:22:40 Uploading - Uploading generated training model\u001b[32mEpoch 0:   8%|▊         | 60/727 [00:18<03:22,  3.29it/s, loss=0.725, v_num=0, train_loss=0.731]\u001b[0m\n",
      "\u001b[32mEpoch 0:   8%|▊         | 60/727 [00:18<03:22,  3.29it/s, loss=0.725, v_num=0, train_loss=0.731]\u001b[0m\n",
      "\u001b[32mEpoch 0:   8%|▊         | 60/727 [00:18<03:22,  3.29it/s, loss=0.667, v_num=0, train_loss=0.628]\u001b[0m\n",
      "\u001b[34mEpoch 0:   8%|▊         | 60/727 [00:17<03:12,  3.46it/s, loss=0.801, v_num=0, train_loss=0.785]#015Epoch 0:   8%|▊         | 60/727 [00:17<03:12,  3.46it/s, loss=0.801, v_num=0, train_loss=0.785]\u001b[0m\n",
      "\u001b[34mEpoch 0:   8%|▊         | 60/727 [00:17<03:13,  3.45it/s, loss=0.744, v_num=0, train_loss=0.705]\u001b[0m\n",
      "\u001b[32mEpoch 0:  12%|█▏        | 90/727 [00:27<03:12,  3.30it/s, loss=0.667, v_num=0, train_loss=0.628]\u001b[0m\n",
      "\u001b[32mEpoch 0:  12%|█▏        | 90/727 [00:27<03:12,  3.30it/s, loss=0.667, v_num=0, train_loss=0.628]\u001b[0m\n",
      "\u001b[32mEpoch 0:  12%|█▏        | 90/727 [00:27<03:12,  3.30it/s, loss=0.55, v_num=0, train_loss=0.533]\u001b[0m\n",
      "\u001b[34mEpoch 0:  12%|█▏        | 90/727 [00:25<03:03,  3.47it/s, loss=0.744, v_num=0, train_loss=0.705]#015Epoch 0:  12%|█▏        | 90/727 [00:25<03:03,  3.47it/s, loss=0.744, v_num=0, train_loss=0.705]\u001b[0m\n",
      "\u001b[34mEpoch 0:  12%|█▏        | 90/727 [00:25<03:03,  3.46it/s, loss=0.64, v_num=0, train_loss=0.593]\u001b[0m\n",
      "\u001b[32mEpoch 0:  17%|█▋        | 120/727 [00:36<03:03,  3.31it/s, loss=0.55, v_num=0, train_loss=0.533]\u001b[0m\n",
      "\u001b[32mEpoch 0:  17%|█▋        | 120/727 [00:36<03:03,  3.31it/s, loss=0.55, v_num=0, train_loss=0.533]\u001b[0m\n",
      "\u001b[32mEpoch 0:  17%|█▋        | 120/727 [00:36<03:03,  3.31it/s, loss=0.42, v_num=0, train_loss=0.357]\u001b[0m\n",
      "\u001b[34mEpoch 0:  17%|█▋        | 120/727 [00:34<02:55,  3.46it/s, loss=0.64, v_num=0, train_loss=0.593]\u001b[0m\n",
      "\u001b[34mEpoch 0:  17%|█▋        | 120/727 [00:34<02:55,  3.46it/s, loss=0.64, v_num=0, train_loss=0.593]\u001b[0m\n",
      "\u001b[34mEpoch 0:  17%|█▋        | 120/727 [00:34<02:55,  3.46it/s, loss=0.471, v_num=0, train_loss=0.400]\u001b[0m\n",
      "\u001b[32mEpoch 0:  21%|██        | 150/727 [00:45<02:54,  3.31it/s, loss=0.42, v_num=0, train_loss=0.357]\u001b[0m\n",
      "\u001b[32mEpoch 0:  21%|██        | 150/727 [00:45<02:54,  3.31it/s, loss=0.42, v_num=0, train_loss=0.357]\u001b[0m\n",
      "\u001b[32mEpoch 0:  21%|██        | 150/727 [00:45<02:54,  3.31it/s, loss=0.345, v_num=0, train_loss=0.277]\u001b[0m\n",
      "\u001b[34mEpoch 0:  21%|██        | 150/727 [00:43<02:46,  3.46it/s, loss=0.471, v_num=0, train_loss=0.400]\u001b[0m\n",
      "\u001b[34mEpoch 0:  21%|██        | 150/727 [00:43<02:46,  3.46it/s, loss=0.471, v_num=0, train_loss=0.400]\u001b[0m\n",
      "\u001b[34mEpoch 0:  21%|██        | 150/727 [00:43<02:46,  3.46it/s, loss=0.32, v_num=0, train_loss=0.329]\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0\u001b[0m\n",
      "\u001b[32m,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [10\u001b[0m\n",
      "\u001b[32m,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0\u001b[0m\n",
      "\u001b[32m,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115\u001b[0m\n",
      "\u001b[32m: operator(): block: [0,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu\u001b[0m\n",
      "\u001b[32m:115: operator(): block: [0,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one\u001b[0m\n",
      "\u001b[32m` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[32mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 723, in _call_and_handle_interrupt\u001b[0m\n",
      "\u001b[32mreturn trainer_fn(*args, **kwargs)\u001b[0m\n",
      "\u001b[32mFile \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\u001b[0m\n",
      "\u001b[32mresults = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\u001b[0m\n",
      "\u001b[32mresults = self._run_stage()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\u001b[0m\n",
      "\u001b[32mreturn self._run_train()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\u001b[0m\n",
      "\u001b[32mself.fit_loop.run()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 204, in run\u001b[0m\n",
      "\u001b[32mself.advance(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 266, in advance\u001b[0m\n",
      "\u001b[32mself._outputs = self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 204, in run\u001b[0m\n",
      "\u001b[32mself.advance(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 208, in advance\u001b[0m\n",
      "\u001b[32mbatch_output = self.batch_loop.run(batch, batch_idx)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 204, in run\u001b[0m\n",
      "\u001b[32mself.advance(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 88, in advance\u001b[0m\n",
      "\u001b[32moutputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 204, in run\u001b[0m\n",
      "\u001b[32mself.advance(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 203, in advance\u001b[0m\n",
      "\u001b[32mresult = self._run_optimization(\u001b[0m\n",
      "\u001b[32mFile \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 256, in _run_optimization\u001b[0m\n",
      "\u001b[32mself._optimizer_step(optimizer, opt_idx, batch_idx, closure)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 369, in _optimizer_step\u001b[0m\n",
      "\u001b[32mself.trainer._call_lightning_module_hook(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1595, in _call_lightning_module_hook\u001b[0m\n",
      "\u001b[32moutput = fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py\", line 1646, in optimizer_step\u001b[0m\n",
      "\u001b[32moptimizer.step(closure=optimizer_closure)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py\", line 168, in step\u001b[0m\n",
      "\u001b[32mstep_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py\", line 193, in optimizer_step\u001b[0m\n",
      "\u001b[32mreturn self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 155, in optimizer_step\u001b[0m\n",
      "\u001b[32mreturn optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\u001b[0m\n",
      "\u001b[32mreturn wrapped(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\u001b[0m\n",
      "\u001b[32mreturn func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/optimization.py\", line 333, in step\u001b[0m\n",
      "\u001b[32mloss = closure()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 140, in _wrap_closure\u001b[0m\n",
      "\u001b[32mclosure_result = closure()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 148, in __call__\u001b[0m\n",
      "\u001b[32mself._result = self.closure(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 143, in closure\u001b[0m\n",
      "\u001b[32mself._backward_fn(step_output.closure_loss)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 311, in backward_fn\u001b[0m\n",
      "\u001b[32mself.trainer._call_strategy_hook(\"backward\", loss, optimizer, opt_idx)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1765, in _call_strategy_hook\u001b[0m\n",
      "\u001b[32moutput = fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py\", line 168, in backward\u001b[0m\n",
      "\u001b[32mself.precision_plugin.backward(self.lightning_module, closure_loss, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 80, in backward\u001b[0m\n",
      "\u001b[32mmodel.backward(closure_loss, optimizer, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py\", line 1391, in backward\u001b[0m\n",
      "\u001b[32mloss.backward(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/_tensor.py\", line 363, in backward\u001b[0m\n",
      "\u001b[32mtorch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 173, in backward\u001b[0m\n",
      "\u001b[32mVariable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\u001b[0m\n",
      "\u001b[32mRuntimeError: CUDA error: device-side assert triggered\u001b[0m\n",
      "\u001b[32mCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\u001b[0m\n",
      "\u001b[32mFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\u001b[0m\n",
      "\u001b[32mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[32mTraceback (most recent call last):\u001b[0m\n",
      "\u001b[32mFile \"multibert.py\", line 147, in <module>\u001b[0m\n",
      "\u001b[32mmultibert_classifier = model(train_df)\n",
      "  File \"multibert.py\", line 76, in model\n",
      "    train_model(LABEL_COLUMNS, warmup_steps, total_training_steps, data_module)\n",
      "  File \"/opt/ml/code/create_model.py\", line 308, in train_model\u001b[0m\n",
      "\u001b[32mtrainer.fit(model, data_module)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 770, in fit\u001b[0m\n",
      "\u001b[32mself._call_and_handle_interrupt(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 738, in _call_and_handle_interrupt\u001b[0m\n",
      "\u001b[32mself._teardown()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1300, in _teardown\u001b[0m\n",
      "\u001b[32mself.strategy.teardown()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py\", line 93, in teardown\u001b[0m\n",
      "\u001b[32msuper().teardown()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py\", line 444, in teardown\u001b[0m\n",
      "\u001b[32moptimizers_to_device(self.optimizers, torch.device(\"cpu\"))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/optimizer.py\", line 27, in optimizers_to_device\u001b[0m\n",
      "\u001b[32moptimizer_to_device(opt, device)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/optimizer.py\", line 33, in optimizer_to_device\u001b[0m\n",
      "\u001b[32moptimizer.state[p] = apply_to_collection(v, torch.Tensor, move_data_to_device, device)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 107, in apply_to_collection\u001b[0m\n",
      "\u001b[32mv = apply_to_collection(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 99, in apply_to_collection\u001b[0m\n",
      "\u001b[32mreturn function(data, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 354, in move_data_to_device\u001b[0m\n",
      "\u001b[32mreturn apply_to_collection(batch, dtype=dtype, function=batch_to)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 99, in apply_to_collection\u001b[0m\n",
      "\u001b[32mreturn function(data, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 347, in batch_to\u001b[0m\n",
      "\u001b[32mdata_output = data.to(device, **kwargs)\u001b[0m\n",
      "\u001b[32mRuntimeError: CUDA error: device-side assert triggered\u001b[0m\n",
      "\u001b[32mCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\u001b[0m\n",
      "\u001b[32mFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\u001b[0m\n",
      "\u001b[32m2022-07-18 19:23:03,356 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[32m2022-07-18 19:23:03,357 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\u001b[0m\n",
      "\u001b[32m2022-07-18 19:23:03,357 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[32m2022-07-18 19:23:03,357 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[32mExitCode 1\u001b[0m\n",
      "\u001b[32mErrorMessage \"RuntimeError: CUDA error: device-side assert triggered\n",
      " CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      " For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      " \n",
      " During handling of the above exception, another exception occurred\n",
      " Traceback (most recent call last)\n",
      " File \"multibert.py\", line 147, in <module>\n",
      " multibert_classifier = model(train_df)\n",
      " File \"multibert.py\", line 76, in model\n",
      " train_model(LABEL_COLUMNS, warmup_steps, total_training_steps, data_module)\n",
      " File \"/opt/ml/code/create_model.py\", line 308, in train_model\n",
      " trainer.fit(model, data_module)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 770, in fit\n",
      " self._call_and_handle_interrupt(\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 738, in _call_and_handle_interrupt\n",
      " self._teardown()\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1300, in _teardown\n",
      " self.strategy.teardown()\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py\", line 93, in teardown\n",
      " super().teardown()\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py\", line 444, in teardown\n",
      " optimizers_to_device(self.optimizers, torch.device(\"cpu\"))\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/optimizer.py\", line 27, in optimizers_to_device\n",
      " optimizer_to_device(opt, device)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/optimizer.py\", line 33, in optimizer_to_device\n",
      " optimizer.state[p] = apply_to_collection(v, torch.Tensor, move_data_to_device, device)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 107, in apply_to_collection\n",
      " v = apply_to_collection(\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 99, in apply_to_collection\n",
      " return function(data, *args, **kwargs)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 354, in move_data_to_device\n",
      " return apply_to_collection(batch, dtype=dtype, function=batch_to)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 347, in batch_to\n",
      " data_output = data.to(device, **kwargs)\"\u001b[0m\n",
      "\u001b[32mCommand \"/opt/conda/bin/python3.8 multibert.py --batch-size 32 --epochs 4 --learning-rate 2e-05\"\u001b[0m\n",
      "\u001b[32m2022-07-18 19:23:03,357 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\n",
      "2022-07-18 19:23:16 Failed - Training job failed\n",
      "\u001b[34mEpoch 0:  25%|██▍       | 180/727 [00:52<02:38,  3.45it/s, loss=0.32, v_num=0, train_loss=0.329]#015Epoch 0:  25%|██▍       | 180/727 [00:52<02:38,  3.45it/s, loss=0.32, v_num=0, train_loss=0.329]\u001b[0m\n",
      "\u001b[34mEpoch 0:  25%|██▍       | 180/727 [00:52<02:38,  3.45it/s, loss=0.279, v_num=0, train_loss=0.260]\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115\u001b[0m\n",
      "\u001b[34m: operator(): block: [0,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0\u001b[0m\n",
      "\u001b[34m,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [47,0\u001b[0m\n",
      "\u001b[34m,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0\u001b[0m\n",
      "\u001b[34m,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0\u001b[0m\n",
      "\u001b[34m,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34m../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: [0,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 723, in _call_and_handle_interrupt\u001b[0m\n",
      "\u001b[34mreturn trainer_fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\u001b[0m\n",
      "\u001b[34mresults = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\u001b[0m\n",
      "\u001b[34mresults = self._run_stage()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\u001b[0m\n",
      "\u001b[34mreturn self._run_train()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\u001b[0m\n",
      "\u001b[34mself.fit_loop.run()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 204, in run\u001b[0m\n",
      "\u001b[34mself.advance(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 266, in advance\u001b[0m\n",
      "\u001b[34mself._outputs = self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 204, in run\u001b[0m\n",
      "\u001b[34mself.advance(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 208, in advance\u001b[0m\n",
      "\u001b[34mbatch_output = self.batch_loop.run(batch, batch_idx)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 204, in run\u001b[0m\n",
      "\u001b[34mself.advance(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 88, in advance\u001b[0m\n",
      "\u001b[34moutputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 204, in run\u001b[0m\n",
      "\u001b[34mself.advance(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 203, in advance\u001b[0m\n",
      "\u001b[34mresult = self._run_optimization(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 256, in _run_optimization\u001b[0m\n",
      "\u001b[34mself._optimizer_step(optimizer, opt_idx, batch_idx, closure)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 369, in _optimizer_step\u001b[0m\n",
      "\u001b[34mself.trainer._call_lightning_module_hook(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1595, in _call_lightning_module_hook\u001b[0m\n",
      "\u001b[34moutput = fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py\", line 1646, in optimizer_step\u001b[0m\n",
      "\u001b[34moptimizer.step(closure=optimizer_closure)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py\", line 168, in step\u001b[0m\n",
      "\u001b[34mstep_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py\", line 193, in optimizer_step\u001b[0m\n",
      "\u001b[34mreturn self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 155, in optimizer_step\u001b[0m\n",
      "\u001b[34mreturn optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\u001b[0m\n",
      "\u001b[34mreturn wrapped(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\u001b[0m\n",
      "\u001b[34mreturn func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/optimization.py\", line 333, in step\u001b[0m\n",
      "\u001b[34mloss = closure()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 140, in _wrap_closure\u001b[0m\n",
      "\u001b[34mclosure_result = closure()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 148, in __call__\u001b[0m\n",
      "\u001b[34mself._result = self.closure(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 143, in closure\u001b[0m\n",
      "\u001b[34mself._backward_fn(step_output.closure_loss)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 311, in backward_fn\u001b[0m\n",
      "\u001b[34mself.trainer._call_strategy_hook(\"backward\", loss, optimizer, opt_idx)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1765, in _call_strategy_hook\u001b[0m\n",
      "\u001b[34moutput = fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py\", line 168, in backward\u001b[0m\n",
      "\u001b[34mself.precision_plugin.backward(self.lightning_module, closure_loss, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 80, in backward\u001b[0m\n",
      "\u001b[34mmodel.backward(closure_loss, optimizer, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py\", line 1391, in backward\u001b[0m\n",
      "\u001b[34mloss.backward(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/_tensor.py\", line 363, in backward\u001b[0m\n",
      "\u001b[34mtorch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 173, in backward\u001b[0m\n",
      "\u001b[34mVariable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\u001b[0m\n",
      "\u001b[34mRuntimeError\u001b[0m\n",
      "\u001b[34m: CUDA error: device-side assert triggered\u001b[0m\n",
      "\u001b[34mCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\u001b[0m\n",
      "\u001b[34mFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"multibert.py\", line 147, in <module>\u001b[0m\n",
      "\u001b[34mmultibert_classifier = model(train_df)\n",
      "  File \"multibert.py\", line 76, in model\n",
      "    train_model(LABEL_COLUMNS, warmup_steps, total_training_steps, data_module)\n",
      "  File \"/opt/ml/code/create_model.py\", line 308, in train_model\u001b[0m\n",
      "\u001b[34mtrainer.fit(model, data_module)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 770, in fit\u001b[0m\n",
      "\u001b[34mself._call_and_handle_interrupt(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 738, in _call_and_handle_interrupt\u001b[0m\n",
      "\u001b[34mself._teardown()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1300, in _teardown\u001b[0m\n",
      "\u001b[34mself.strategy.teardown()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py\", line 93, in teardown\u001b[0m\n",
      "\u001b[34msuper().teardown()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py\", line 444, in teardown\u001b[0m\n",
      "\u001b[34moptimizers_to_device(self.optimizers, torch.device(\"cpu\"))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/optimizer.py\", line 27, in optimizers_to_device\u001b[0m\n",
      "\u001b[34moptimizer_to_device(opt, device)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/optimizer.py\", line 33, in optimizer_to_device\u001b[0m\n",
      "\u001b[34moptimizer.state[p] = apply_to_collection(v, torch.Tensor, move_data_to_device, device)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 107, in apply_to_collection\u001b[0m\n",
      "\u001b[34mv = apply_to_collection(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 99, in apply_to_collection\u001b[0m\n",
      "\u001b[34mreturn function(data, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 354, in move_data_to_device\u001b[0m\n",
      "\u001b[34mreturn apply_to_collection(batch, dtype=dtype, function=batch_to)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 99, in apply_to_collection\u001b[0m\n",
      "\u001b[34mreturn function(data, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 347, in batch_to\u001b[0m\n",
      "\u001b[34mdata_output = data.to(device, **kwargs)\u001b[0m\n",
      "\u001b[34mRuntimeError: CUDA error: device-side assert triggered\u001b[0m\n",
      "\u001b[34mCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\u001b[0m\n",
      "\u001b[34mFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\u001b[0m\n",
      "\u001b[34m2022-07-18 19:23:08,164 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2022-07-18 19:23:08,164 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\u001b[0m\n",
      "\u001b[34m2022-07-18 19:23:08,165 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2022-07-18 19:23:08,165 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"RuntimeError\n",
      " CUDA error: device-side assert triggered\n",
      " CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      " For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      " \n",
      " During handling of the above exception, another exception occurred\n",
      " Traceback (most recent call last)\n",
      " File \"multibert.py\", line 147, in <module>\n",
      " multibert_classifier = model(train_df)\n",
      " File \"multibert.py\", line 76, in model\n",
      " train_model(LABEL_COLUMNS, warmup_steps, total_training_steps, data_module)\n",
      " File \"/opt/ml/code/create_model.py\", line 308, in train_model\n",
      " trainer.fit(model, data_module)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 770, in fit\n",
      " self._call_and_handle_interrupt(\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 738, in _call_and_handle_interrupt\n",
      " self._teardown()\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1300, in _teardown\n",
      " self.strategy.teardown()\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py\", line 93, in teardown\n",
      " super().teardown()\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py\", line 444, in teardown\n",
      " optimizers_to_device(self.optimizers, torch.device(\"cpu\"))\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/optimizer.py\", line 27, in optimizers_to_device\n",
      " optimizer_to_device(opt, device)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/optimizer.py\", line 33, in optimizer_to_device\n",
      " optimizer.state[p] = apply_to_collection(v, torch.Tensor, move_data_to_device, device)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 107, in apply_to_collection\n",
      " v = apply_to_collection(\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 99, in apply_to_collection\n",
      " return function(data, *args, **kwargs)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 354, in move_data_to_device\n",
      " return apply_to_collection(batch, dtype=dtype, function=batch_to)\n",
      " File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\", line 347, in batch_to\n",
      " data_output = data.to(device, **kwargs)\n",
      " RuntimeError: CUDA error: device-side assert triggered\"\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python3.8 multibert.py --batch-size 32 --epochs 4 --learning-rate 2e-05\"\u001b[0m\n",
      "\u001b[34m2022-07-18 19:23:08,165 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job pytorch-training-2022-07-18-19-16-20-052: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"RuntimeError: CUDA error: device-side assert triggered\n CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n \n During handling of the above exception, another exception occurred\n Traceback (most recent call last)\n File \"multibert.py\", line 147, in <module>\n multibert_classifier = model(train_df)\n File \"multibert.py\", line 76, in model\n train_model(LABEL_COLUMNS, warmup_steps, total_training_steps, data_module)\n File \"/opt/ml/code/create_model.py\", line 308, in train_model\n trainer.fit(model, data_module)\n File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 770, in fit\n self._call_and_handle_interrupt(\n File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 738, in _call_and_handle_interrupt\n self._teardown()\n File \"/opt/conda/lib/python3.8/site-packages/p",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q_/glkcp8_n5h300xwrkqscmh9c0000gn/T/ipykernel_28998/4232306621.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# cell 07\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpytorch_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#pytorch_estimator.fit({'train': training_data_uri,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#                       'test': test_data_uri})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2080\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2082\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2083\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3851\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3852\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3853\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3387\u001b[0m                     \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3388\u001b[0m                 )\n\u001b[0;32m-> 3389\u001b[0;31m             raise exceptions.UnexpectedStatusException(\n\u001b[0m\u001b[1;32m   3390\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job pytorch-training-2022-07-18-19-16-20-052: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"RuntimeError: CUDA error: device-side assert triggered\n CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n \n During handling of the above exception, another exception occurred\n Traceback (most recent call last)\n File \"multibert.py\", line 147, in <module>\n multibert_classifier = model(train_df)\n File \"multibert.py\", line 76, in model\n train_model(LABEL_COLUMNS, warmup_steps, total_training_steps, data_module)\n File \"/opt/ml/code/create_model.py\", line 308, in train_model\n trainer.fit(model, data_module)\n File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 770, in fit\n self._call_and_handle_interrupt(\n File \"/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 738, in _call_and_handle_interrupt\n self._teardown()\n File \"/opt/conda/lib/python3.8/site-packages/p"
     ]
    }
   ],
   "source": [
    "# cell 07\n",
    "pytorch_estimator.fit(training_data_uri)\n",
    "#pytorch_estimator.fit({'train': training_data_uri,\n",
    "#                       'test': test_data_uri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 09\n",
    "predictor = pytorch_estimator.deploy(instance_type='ml.g4dn.xlarge',\n",
    "                                     initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 11\n",
    "data = \"I am a test.\"\n",
    "response = predictor.predict(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
